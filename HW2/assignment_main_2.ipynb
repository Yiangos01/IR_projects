{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Unstructured and Structured Data #\n",
    "## Assignment 1: Retrieval models [100 points] ##\n",
    "**TA**: Nikos Voskarides (n.voskarides@uva.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will get familiar with basic information retrieval concepts. You will implement and evaluate different information retrieval ranking models and evaluate their performance.\n",
    "\n",
    "We provide you with a Indri index. To query the index, you'll use a Python package ([pyndri](https://github.com/cvangysel/pyndri)) that allows easy access to the underlying document statistics.\n",
    "\n",
    "For evaluation you'll use the [TREC Eval](https://github.com/usnistgov/trec_eval) utility, provided by the National Institute of Standards and Technology of the United States. TREC Eval is the de facto standard way to compute Information Retrieval measures and is frequently referenced in scientific papers.\n",
    "\n",
    "This is a **groups-of-three assignment**, the deadline is **Monday, 22/1, at 23:59**. Code quality, informative comments and convincing analysis of the results will be considered when grading. Submission should be done through blackboard, questions can be asked on the course [Piazza](https://piazza.com/class/ixoz63p156g1ts).\n",
    "\n",
    "### Technicalities (must-read!) ###\n",
    "\n",
    "The assignment directory is organized as follows:\n",
    "   * `./assignment.ipynb` (this file): the description of the assignment.\n",
    "   * `./index/`: the index we prepared for you.\n",
    "   * `./ap_88_90/`: directory with ground-truth and evaluation sets:\n",
    "      * `qrel_test`: test query relevance collection (**test set**).\n",
    "      * `qrel_validation`: validation query relevance collection (**validation set**).\n",
    "      * `topics_title`: semicolon-separated file with query identifiers and terms.\n",
    "\n",
    "You will need the following software packages (tested with Python 3.5 inside [Anaconda](https://conda.io/docs/user-guide/install/index.html)):\n",
    "   * Python 3.5 and Jupyter\n",
    "   * Indri + Pyndri (Follow the installation instructions [here](https://github.com/nickvosk/pyndri/blob/master/README.md))\n",
    "   * gensim [link](https://radimrehurek.com/gensim/install.html)\n",
    "   * TREC Eval [link](https://github.com/usnistgov/trec_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TREC Eval primer ###\n",
    "The TREC Eval utility can be downloaded and compiled as follows:\n",
    "\n",
    "    git clone https://github.com/usnistgov/trec_eval.git\n",
    "    cd trec_eval\n",
    "    make\n",
    "\n",
    "TREC Eval computes evaluation scores given two files: ground-truth information regarding relevant documents, named *query relevance* or *qrel*, and a ranking of documents for a set of queries, referred to as a *run*. The *qrel* will be supplied by us and should not be changed. For every retrieval model (or combinations thereof) you will generate a run of the top-1000 documents for every query. The format of the *run* file is as follows:\n",
    "\n",
    "    $query_identifier Q0 $document_identifier $rank_of_document_for_query $query_document_similarity $run_identifier\n",
    "    \n",
    "where\n",
    "   * `$query_identifier` is the unique identifier corresponding to a query (usually this follows a sequential numbering).\n",
    "   * `Q0` is a legacy field that you can ignore.\n",
    "   * `$document_identifier` corresponds to the unique identifier of a document (e.g., APXXXXXXX where AP denotes the collection and the Xs correspond to a unique numerical identifier).\n",
    "   * `$rank_of_document_for_query` denotes the rank of the document for the particular query. This field is ignored by TREC Eval and is only maintained for legacy support. The ranks are computed by TREC Eval itself using the `$query_document_similarity` field (see next). However, it remains good practice to correctly compute this field.\n",
    "   * `$query_document_similarity` is a score indicating the similarity between query and document where a higher score denotes greater similarity.\n",
    "   * `$run_identifier` is an identifier of the run. This field is for your own convenience and has no purpose beyond bookkeeping.\n",
    "   \n",
    "For example, say we have two queries: `Q1` and `Q2` and we rank three documents (`DOC1`, `DOC2`, `DOC3`). For query `Q1`, we find the following similarity scores `score(Q1, DOC1) = 1.0`, `score(Q1, DOC2) = 0.5`, `score(Q1, DOC3) = 0.75`; and for `Q2`: `score(Q2, DOC1) = -0.1`, `score(Q2, DOC2) = 1.25`, `score(Q1, DOC3) = 0.0`. We can generate run using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 Q0 DOC1 1 1.0 example\n",
      "Q1 Q0 DOC3 2 0.75 example\n",
      "Q1 Q0 DOC2 3 0.5 example\n",
      "Q2 Q0 DOC2 1 1.25 example\n",
      "Q2 Q0 DOC3 2 0.0 example\n",
      "Q2 Q0 DOC1 3 -0.1 example\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def write_run(model_name, data, out_f,\n",
    "              max_objects_per_query=sys.maxsize,\n",
    "              skip_sorting=False):\n",
    "    \"\"\"\n",
    "    Write a run to an output file.\n",
    "    Parameters:\n",
    "        - model_name: identifier of run.\n",
    "        - data: dictionary mapping topic_id to object_assesments;\n",
    "            object_assesments is an iterable (list or tuple) of\n",
    "            (relevance, object_id) pairs.\n",
    "            The object_assesments iterable is sorted by decreasing order.\n",
    "        - out_f: output file stream.\n",
    "        - max_objects_per_query: cut-off for number of objects per query.\n",
    "    \"\"\"\n",
    "    for subject_id, object_assesments in data.items():\n",
    "        if not object_assesments:\n",
    "            logging.warning('Received empty ranking for %s; ignoring.',\n",
    "                            subject_id)\n",
    "\n",
    "            continue\n",
    "\n",
    "        # Probe types, to make sure everything goes alright.\n",
    "        # assert isinstance(object_assesments[0][0], float) or \\\n",
    "        #     isinstance(object_assesments[0][0], np.float32)\n",
    "        assert isinstance(object_assesments[0][1], str) or \\\n",
    "            isinstance(object_assesments[0][1], bytes)\n",
    "\n",
    "        if not skip_sorting:\n",
    "            object_assesments = sorted(object_assesments, reverse=True)\n",
    "\n",
    "        if max_objects_per_query < sys.maxsize:\n",
    "            object_assesments = object_assesments[:max_objects_per_query]\n",
    "\n",
    "        if isinstance(subject_id, bytes):\n",
    "            subject_id = subject_id.decode('utf8')\n",
    "\n",
    "        for rank, (relevance, object_id) in enumerate(object_assesments):\n",
    "            if isinstance(object_id, bytes):\n",
    "                object_id = object_id.decode('utf8')\n",
    "\n",
    "            out_f.write(\n",
    "                '{subject} Q0 {object} {rank} {relevance} '\n",
    "                '{model_name}\\n'.format(\n",
    "                    subject=subject_id,\n",
    "                    object=object_id,\n",
    "                    rank=rank + 1,\n",
    "                    relevance=relevance,\n",
    "                    model_name=model_name))\n",
    "            \n",
    "# The following writes the run to standard output.\n",
    "# In your code, you should write the runs to local\n",
    "# storage in order to pass them to trec_eval.\n",
    "write_run(\n",
    "    model_name='example',\n",
    "    data={\n",
    "        'Q1': ((1.0, 'DOC1'), (0.5, 'DOC2'), (0.75, 'DOC3')),\n",
    "        'Q2': ((-0.1, 'DOC1'), (1.25, 'DOC2'), (0.0, 'DOC3')),\n",
    "    },\n",
    "    out_f=sys.stdout,\n",
    "    max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that we know that `DOC1` is relevant and `DOC3` is non-relevant for `Q1`. In addition, for `Q2` we only know of the relevance of `DOC3`. The query relevance file looks like:\n",
    "\n",
    "    Q1 0 DOC1 1\n",
    "    Q1 0 DOC3 0\n",
    "    Q2 0 DOC3 1\n",
    "    \n",
    "We store the run and qrel in files `example.run` and `example.qrel` respectively on disk. We can now use TREC Eval to compute evaluation measures. In this example, we're only interested in Mean Average Precision and we'll only show this below for brevity. However, TREC Eval outputs much more information such as NDCG, recall, precision, etc.\n",
    "\n",
    "    $ trec_eval -m all_trec -q example.qrel example.run | grep -E \"^map\\s\"\n",
    "    > map                   \tQ1\t1.0000\n",
    "    > map                   \tQ2\t0.5000\n",
    "    > map                   \tall\t0.7500\n",
    "    \n",
    "Now that we've discussed the output format of rankings and how you can compute evaluation measures from these rankings, we'll now proceed with an overview of the indexing framework you'll use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyndri primer ###\n",
    "For this assignment you will use [Pyndri](https://github.com/cvangysel/pyndri) [[1](https://arxiv.org/abs/1701.00749)], a python interface for [Indri](https://www.lemurproject.org/indri.php). We have indexed the document collection and you can query the index using Pyndri. We will start by giving you some examples of what Pyndri can do:\n",
    "\n",
    "First we read the document collection index with Pyndri:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyndri\n",
    "\n",
    "index = pyndri.Index('index/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded index can be used to access a collection of documents in an easy manner. We'll give you some examples to get some idea of what it can do, it is up to you to figure out how to use it for the remainder of the assignment.\n",
    "\n",
    "First let's look at the number of documents, since Pyndri indexes the documents using incremental identifiers we can simply take the lowest index and the maximum document and consider the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 164597 documents in this collection.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d documents in this collection.\" % (index.maximum_document() - index.document_base()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first document out of the collection and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP890425-0001\n"
     ]
    }
   ],
   "source": [
    "example_document = index.document(index.document_base())\n",
    "print(example_document[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a document consists of two things, a string representing the external document identifier and an integer list representing the identifiers of words that make up the document. Pyndri uses integer representations for words or terms, thus a token_id is an integer that represents a word whereas the token is the actual text of the word/term. Every id has a unique token and vice versa with the exception of stop words: words so common that there are uninformative, all of these receive the zero id.\n",
    "\n",
    "To see what some ids and their matching tokens we take a look at the dictionary of the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'new'), (2, 'percent'), (3, 'two'), (4, '1'), (5, 'people'), (6, 'million'), (7, '000'), (8, 'government'), (9, 'president'), (10, 'years'), (11, 'state'), (12, '2'), (13, 'states'), (14, 'three'), (15, 'time')]\n"
     ]
    }
   ],
   "source": [
    "token2id, id2token, _ = index.get_dictionary()\n",
    "print(list(id2token.items())[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this dictionary we can see the tokens for the (non-stop) words in our example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['52', 'students', 'arrested', 'takeover', 'university', 'massachusetts', 'building', 'fifty', 'two', 'students', 'arrested', 'tuesday', 'evening', 'occupying', 'university', 'massachusetts', 'building', 'overnight', 'protest', 'defense', 'department', 'funded', 'research', 'new', 'york', 'city', 'thousands', 'city', 'college', 'students', 'got', 'unscheduled', 'holiday', 'demonstrators', 'occupied', 'campus', 'administration', 'building', 'protest', 'possible', 'tuition', 'increases', 'prompting', 'officials', 'suspend', 'classes', '60', 'police', 'riot', 'gear', 'arrived', 'university', 'massachusetts', '5', 'p', 'm', 'two', 'hours', 'later', 'bus', 'drove', 'away', '29', 'students', 'camped', 'memorial', 'hall', 'students', 'charged', 'trespassing', '23', 'students', 'arrested', 'lying', 'bus', 'prevent', 'leaving', 'police', '300', 'students', 'stood', 'building', 'chanting', 'looking', 'students', 'hall', 'arrested', '35', 'students', 'occupied', 'memorial', 'hall', '1', 'p', 'm', 'monday', 'declined', 'offer', 'meet', 'administrators', 'provosts', 'office', 'tuesday', 'morning', 'presented', 'list', 'demands', 'halt', 'defense', 'department', 'research', '25', '000', 'student', 'campus', '40', 'students', 'left', 'building', 'tuesday', 'morning', 'university', 'administrators', 'told', 'arrested', '5', 'p', 'm', 'university', 'spokeswoman', 'jeanne', 'hopkins', 'takeover', 'second', 'western', 'massachusetts', 'campus', 'seven', 'protesters', 'arrested', 'april', '19', 'charges', 'disorderly', 'conduct', 'trespassing', 'demonstrating', 'military', 'funded', 'research', 'campus', 'particularly', 'research', 'anthrax', 'research', 'university', 'non', 'classified', 'researchers', 'make', 'work', 'public', 'university', 'rules', '11', '6', 'million', '22', 'percent', 'grant', 'money', 'received', 'university', 'came', 'defense', 'department', '1988', 'school', 'chancellor', 'joseph', 'd', 'duffey', 'issued', 'statement', 'telling', 'students', 'research', 'continue', 'campus', 'school', 'administrators', 'decide', 'differently', 'policy', 'negotiated', 'students', 'duffey', 'latest', 'occupation', 'began', 'students', 'rallying', 'monday', 'student', 'union', 'military', 'research', 'marched', 'administration', 'building', 'ducked', 'memorial', 'hall', 'en', 'route', 'followed', 'members', 'local', 'chapter', 'american', 'friends', 'service', 'committee', 'contended', 'research', 'dangerous', 'town', 'promotes', 'militarism', 'banned', 'university', 'argued', 'purpose', 'anthrax', 'research', 'peaceful', 'strain', 'bacteria', 'non', 'virulent', 'study', 'school', '23', 'years', 'incident', 'amherst', 'health', 'board', 'scheduled', 'hearing', 'wednesday', 'question', 'safety', 'anthrax', 'research', 'tuesday', 'time', '1969', 'classes', 'city', 'college', 'new', 'york', 'canceled', 'student', 'protests', 'school', 'spokesman', 'charles', 'deciccio', 'protesters', 'demanding', 'face', 'face', 'meeting', 'gov', 'mario', 'cuomo', 'feared', 'tuition', 'college', '1', '250', 'increased', 'college', 'staff', 'reduced', 'state', 'budget', 'cuts', 'governor', 'immediate', 'comment', 'tuition', 'set', 'deciccio']\n"
     ]
    }
   ],
   "source": [
    "print([id2token[word_id] for word_id in example_document[1] if word_id > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reverse can also be done, say we want to look for news about the \"University of Massachusetts\", the tokens of that query can be converted to ids using the reverse dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by tokens: ['university', '', 'massachusetts']\n",
      "Query by ids with stopwords: [200, 0, 894]\n",
      "Query by ids without stopwords: [200, 894]\n"
     ]
    }
   ],
   "source": [
    "query_tokens = index.tokenize(\"University of Massachusetts\")\n",
    "print(\"Query by tokens:\", query_tokens)\n",
    "query_id_tokens = [token2id.get(query_token,0) for query_token in query_tokens]\n",
    "print(\"Query by ids with stopwords:\", query_id_tokens)\n",
    "query_id_tokens = [word_id for word_id in query_id_tokens if word_id > 0]\n",
    "print(\"Query by ids without stopwords:\", query_id_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally we can now match the document and query in the id space, let's see how often a word from the query occurs in our example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document AP890425-0001 has 13 word matches with query: \"university  massachusetts\".\n",
      "Document AP890425-0001 and query \"university  massachusetts\" have a 2.5% overlap.\n"
     ]
    }
   ],
   "source": [
    "matching_words = sum([True for word_id in example_document[1] if word_id in query_id_tokens])\n",
    "print(\"Document %s has %d word matches with query: \\\"%s\\\".\" % (example_document[0], matching_words, ' '.join(query_tokens)))\n",
    "print(\"Document %s and query \\\"%s\\\" have a %.01f%% overlap.\" % (example_document[0], ' '.join(query_tokens),matching_words/float(len(example_document[1]))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is certainly not everything Pyndri can do, it should give you an idea of how to use it. Please take a look at the [examples](https://github.com/cvangysel/pyndri) as it will help you a lot with this assignment.\n",
    "\n",
    "**CAUTION**: Avoid printing out the whole index in this Notebook as it will generate a lot of output and is likely to corrupt the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the query file\n",
    "You can parse the query file (`ap_88_89/topics_title`) using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('51', 'Airbus Subsidies'), ('52', 'South African Sanctions'), ('53', 'Leveraged Buyouts'), ('54', 'Satellite Launch Contracts'), ('55', 'Insider Trading'), ('56', 'Prime (Lending) Rate Moves, Predictions'), ('57', 'MCI'), ('58', 'Rail Strikes'), ('59', 'Weather Related Fatalities'), ('60', 'Merit-Pay vs. Seniority'), ('61', 'Israeli Role in Iran-Contra Affair'), ('62', \"Military Coups D'etat\"), ('63', 'Machine Translation'), ('64', 'Hostage-Taking'), ('65', 'Information Retrieval Systems'), ('66', 'Natural Language Processing'), ('67', 'Politically Motivated Civil Disturbances'), ('68', 'Health Hazards from Fine-Diameter Fibers'), ('69', 'Attempts to Revive the SALT II Treaty'), ('70', 'Surrogate Motherhood'), ('71', 'Border Incursions'), ('72', 'Demographic Shifts in the U.S.'), ('73', 'Demographic Shifts across National Boundaries'), ('74', 'Conflicting Policy'), ('75', 'Automation'), ('76', 'U.S. Constitution - Original Intent'), ('77', 'Poaching'), ('78', 'Greenpeace'), ('79', 'FRG Political Party Positions'), ('80', '1988 Presidential Candidates Platforms'), ('81', 'Financial crunch for televangelists in the wake of the PTL scandal'), ('82', 'Genetic Engineering'), ('83', 'Measures to Protect the Atmosphere'), ('84', 'Alternative/renewable Energy Plant & Equipment Installation'), ('85', 'Official Corruption'), ('86', 'Bank Failures'), ('87', 'Criminal Actions Against Officers of Failed Financial Institutions'), ('88', 'Crude Oil Price Trends'), ('89', '\"Downstream\" Investments by OPEC Member States'), ('90', 'Data on Proven Reserves of Oil & Natural Gas Producers'), ('91', 'U.S. Army Acquisition of Advanced Weapons Systems'), ('92', 'International Military Equipment Sales'), ('93', 'What Backing Does the National Rifle Association Have?'), ('94', 'Computer-aided Crime'), ('95', 'Computer-aided Crime Detection'), ('96', 'Computer-Aided Medical Diagnosis'), ('97', 'Fiber Optics Applications'), ('98', 'Fiber Optics Equipment Manufacturers'), ('99', 'Iran-Contra Affair'), ('100', 'Controlling the Transfer of High Technology'), ('101', 'Design of the \"Star Wars\" Anti-missile Defense System'), ('102', \"Laser Research Applicable to the U.S.'s Strategic Defense Initiative\"), ('103', 'Welfare Reform'), ('104', 'Catastrophic Health Insurance'), ('105', '\"Black Monday\"'), ('106', 'U.S. Control of Insider Trading'), ('107', 'Japanese Regulation of Insider Trading'), ('108', 'Japanese Protectionist Measures'), ('109', 'Find Innovative Companies'), ('110', 'Black Resistance Against the South African Government'), ('111', 'Nuclear Proliferation'), ('112', 'Funding Biotechnology'), ('113', 'New Space Satellite Applications'), ('114', 'Non-commercial Satellite Launches'), ('115', 'Impact of the 1986 Immigration Law'), ('116', 'Generic Drug Substitutions'), ('117', 'Capacity of the U.S. Cellular Telephone Network'), ('118', 'International Terrorists'), ('119', 'Actions Against International Terrorists'), ('120', 'Economic Impact of International Terrorism'), ('121', 'Death from Cancer'), ('122', 'RDT&E of New Cancer Fighting Drugs'), ('123', 'Research into & Control of Carcinogens'), ('124', 'Alternatives to Traditional Cancer Therapies'), ('125', 'Anti-smoking Actions by Government'), ('126', 'Medical Ethics and Modern Technology'), ('127', 'U.S.-U.S.S.R. Arms Control Agreements'), ('128', 'Privatization of State Assets'), ('129', 'Soviet Spying on the U.S.'), ('130', 'Jewish Emigration and U.S.-USSR Relations'), ('131', 'McDonnell Douglas Contracts for Military Aircraft'), ('132', '\"Stealth\" Aircraft'), ('133', 'Hubble Space Telescope'), ('134', 'The Human Genome Project'), ('135', 'Possible Contributions of Gene Mapping to Medicine'), ('136', 'Diversification by Pacific Telesis'), ('137', 'Expansion in the U.S. Theme Park Industry'), ('138', 'Iranian Support for Lebanese Hostage-takers'), ('139', \"Iran's Islamic Revolution - Domestic and Foreign Social Consequences\"), ('140', 'Political Impact of Islamic Fundamentalism'), ('141', \"Japan's Handling of its Trade Surplus with the U.S.\"), ('142', 'Impact of Government Regulated Grain Farming on International Relations'), ('143', 'Why Protect U.S. Farmers?'), ('144', 'Management Problems at the United Nations'), ('145', 'Influence of the \"Pro-Israel Lobby\"'), ('146', 'Negotiating an End to the Nicaraguan Civil War'), ('147', 'Productivity Trends in the U.S. Economy'), ('148', 'Conflict in the Horn of Africa'), ('149', 'Industrial Espionage'), ('150', 'U.S. Political Campaign Financing'), ('151', 'Coping with overcrowded prisons'), ('152', 'Accusations of Cheating by Contractors on U.S. Defense Projects'), ('153', 'Insurance Coverage which pays for Long Term Care'), ('154', 'Oil Spills'), ('155', 'Right Wing Christian Fundamentalism in U.S.'), ('156', 'Efforts to enact Gun Control Legislation'), ('157', 'Causes and treatments of multiple sclerosis (MS)'), ('158', 'Term limitations for members of the U.S. Congress'), ('159', 'Electric Car Development'), ('160', 'Vitamins - The Cure for or Cause of Human Ailments'), ('161', 'Acid Rain'), ('162', 'Automobile Recalls'), ('163', 'Vietnam Veterans and Agent Orange'), ('164', 'Generic Drugs - Illegal Activities by Manufacturers'), ('165', 'Tobacco company advertising and the young'), ('166', 'Standardized testing and cultural bias'), ('167', 'Regulation of the showing of violence and explicit sex in motion picture theaters, on television, and on video cassettes.'), ('168', 'Financing AMTRAK'), ('169', 'Cost of Garbage/Trash Removal'), ('170', 'The Consequences of Implantation of Silicone Gel Breast Devices'), ('171', \"Use of Mutual Funds in an Individual's Retirement Strategy\"), ('172', 'The Effectiveness of Medical Products and Related Programs Utilized in the Cessation of Smoking.'), ('173', 'Smoking Bans'), ('174', 'Hazardous Waste Cleanup'), ('175', 'NRA Prevention of Gun Control Legislation'), ('176', 'Real-life private investigators'), ('177', 'English as the Official Language in U.S.'), ('178', 'Dog Maulings'), ('179', 'U. S. Restaurants in Foreign Lands'), ('180', 'Ineffectiveness of U.S. Embargoes/Sanctions'), ('181', 'Abuse of the Elderly by Family Members, and Medical and Nonmedical Personnel, and Initiatives Being Taken to Minimize This Mistreatment'), ('182', 'Commercial Overfishing Creates Food Fish Deficit'), ('183', 'Asbestos Related Lawsuits'), ('184', 'Corporate Pension Plans/Funds'), ('185', 'Reform of the U.S. Welfare System'), ('186', 'Difference of Learning Levels Among Inner City and More Suburban School Students'), ('187', 'Signs of the Demise of Independent Publishing'), ('188', 'Beachfront Erosion'), ('189', 'Real Motives for Murder'), ('190', 'Instances of Fraud Involving the Use of a Computer'), ('191', 'Efforts to Improve U.S. Schooling'), ('192', 'Oil Spill Cleanup'), ('193', 'Toys R Dangerous'), ('194', 'The Amount of Money Earned by Writers'), ('195', 'Stock Market Perturbations Attributable to Computer Initiated Trading'), ('196', 'School Choice Voucher System and its effects upon the entire U.S. educational program'), ('197', 'Reform of the jurisprudence system to stop juries from granting unreasonable monetary awards'), ('198', 'Gene Therapy and Its Benefits to Humankind'), ('199', 'Legality of Medically Assisted Suicides'), ('200', 'Impact of foreign textile imports on U.S. textile industry')])\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import io\n",
    "import logging\n",
    "import sys\n",
    "import time \n",
    "\n",
    "def parse_topics(file_or_files,\n",
    "                 max_topics=sys.maxsize, delimiter=';'):\n",
    "    assert max_topics >= 0 or max_topics is None\n",
    "\n",
    "    topics = collections.OrderedDict()\n",
    "\n",
    "    if not isinstance(file_or_files, list) and \\\n",
    "            not isinstance(file_or_files, tuple):\n",
    "        if hasattr(file_or_files, '__iter__'):\n",
    "            file_or_files = list(file_or_files)\n",
    "        else:\n",
    "            file_or_files = [file_or_files]\n",
    "\n",
    "    for f in file_or_files:\n",
    "        assert isinstance(f, io.IOBase)\n",
    "\n",
    "        for line in f:\n",
    "            assert(isinstance(line, str))\n",
    "\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            topic_id, terms = line.split(delimiter, 1)\n",
    "\n",
    "            if topic_id in topics and (topics[topic_id] != terms):\n",
    "                    logging.error('Duplicate topic \"%s\" (%s vs. %s).',\n",
    "                                  topic_id,\n",
    "                                  topics[topic_id],\n",
    "                                  terms)\n",
    "\n",
    "            topics[topic_id] = terms\n",
    "\n",
    "            if max_topics > 0 and len(topics) >= max_topics:\n",
    "                break\n",
    "\n",
    "    return topics\n",
    "\n",
    "with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "    print(parse_topics([f_topics]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement and compare lexical IR methods [35 points] ### \n",
    "\n",
    "In this task you will implement a number of lexical methods for IR using the **Pyndri** framework. Then you will evaluate these methods on the dataset we have provided using **TREC Eval**.\n",
    "\n",
    "Use the **Pyndri** framework to get statistics of the documents (term frequency, document frequency, collection frequency; **you are not allowed to use the query functionality of Pyndri**) and implement the following scoring methods in **Python**:\n",
    "\n",
    "- [TF-IDF](http://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html) and \n",
    "- [BM25](http://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html) with k1=1.2 and b=0.75. **[5 points]**\n",
    "- Language models ([survey](https://drive.google.com/file/d/0B-zklbckv9CHc0c3b245UW90NE0/view))\n",
    "    - Jelinek-Mercer (explore different values of ð›Œ in the range [0.1, 0.5, 0.9]). **[5 points]**\n",
    "    - Dirichlet Prior (explore different values of ð› [500, 1000, 1500]). **[5 points]**\n",
    "    - Absolute discounting (explore different values of ð›… in the range [0.1, 0.5, 0.9]). **[5 points]**\n",
    "    - [Positional Language Models](http://sifaka.cs.uiuc.edu/~ylv2/pub/sigir09-plm.pdf) define a language model for each position of a document, and score a document based on the scores of its PLMs. The PLM is estimated based on propagated counts of words within a document through a proximity-based density function, which both captures proximity heuristics and achieves an effect of â€œsoftâ€ passage retrieval. Implement the PLM, all five kernels, but only the Best position strategy to score documents. Use ð›” equal to 50, and Dirichlet smoothing with ð› optimized on the validation set (decide how to optimize this value yourself and motivate your decision in the report). **[10 points]**\n",
    "    \n",
    "Implement the above methods and report evaluation measures (on the test set) using the hyper parameter values you optimized on the validation set (also report the values of the hyper parameters). Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "For the language models, create plots showing `NDCG@10` with varying values of the parameters. You can do this by chaining small scripts using shell scripting (preferred) or execute trec_eval using Python's `subprocess`.\n",
    "\n",
    "Compute significance of the results using a [two-tailed paired Student t-test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html) **[5 points]**. Be wary of false rejection of the null hypothesis caused by the [multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). There are multiple ways to mitigate this problem and it is up to you to choose one.\n",
    "\n",
    "Analyse the results by identifying specific queries where different methods succeed or fail and discuss possible reasons that cause these differences. This is *very important* in order to understand who the different retrieval functions behave.\n",
    "\n",
    "**NOTE**: Donâ€™t forget to use log computations in your calculations to avoid underflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: You should structure your code around the helper functions we provide below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering statistics about 456 terms.\n",
      "Inverted index creation took 63.8591685295105 seconds.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "    queries = parse_topics([f_topics])\n",
    "\n",
    "index = pyndri.Index('index/')\n",
    "\n",
    "num_documents = index.maximum_document() - index.document_base()\n",
    "\n",
    "dictionary = pyndri.extract_dictionary(index)\n",
    "\n",
    "tokenized_queries = {\n",
    "    query_id: [dictionary.translate_token(token)\n",
    "               for token in index.tokenize(query_string)\n",
    "               if dictionary.has_token(token)]\n",
    "    for query_id, query_string in queries.items()}\n",
    "\n",
    "query_term_ids = set(\n",
    "    query_term_id\n",
    "    for query_term_ids in tokenized_queries.values()\n",
    "    for query_term_id in query_term_ids)\n",
    "\n",
    "print('Gathering statistics about', len(query_term_ids), 'terms.')\n",
    "\n",
    "# inverted index creation\n",
    "\n",
    "total_terms = 0\n",
    "\n",
    "document_lengths = {}\n",
    "unique_terms_per_document = {}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "inverted_index = collections.defaultdict(dict)\n",
    "collection_frequencies = collections.defaultdict(int)\n",
    "\n",
    "# extended inverted index creation with position of terms in document\n",
    "positional_inverted_index = collections.defaultdict(dict)\n",
    "\n",
    "# extended inverted index creation with position of terms in document\n",
    "positions_of_term_in_document = collections.defaultdict(dict)\n",
    "\n",
    "# Set containing the vocabulary of the words used in the queries\n",
    "query_vocabulary = set()\n",
    "# Set containing the vocabulary from all documents\n",
    "full_vocabulary = set()\n",
    "\n",
    "for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "    ext_doc_id, doc_token_ids = index.document(int_doc_id)\n",
    "\n",
    "#   collecting the frequeuncy of the words (that appear in some query)\n",
    "#   and general statistics about the document\n",
    "    document_bow = collections.Counter(\n",
    "        token_id for token_id in doc_token_ids\n",
    "        if token_id > 0)\n",
    "    document_length = sum(document_bow.values())\n",
    "    \n",
    "#     dictionary with list of positions for this document\n",
    "    positions_dictionary = collections.defaultdict(int)\n",
    "#         ADDED !!! for positional inverted index\n",
    "    for position, token_id in enumerate(doc_token_ids):\n",
    "#         updating the full vocabulary\n",
    "        full_vocabulary.add(token_id)\n",
    "        \n",
    "#         if we are interested for that word (has been found in a query)\n",
    "        if token_id in query_term_ids :\n",
    "        \n",
    "#         updating the query vocabulary\n",
    "            query_vocabulary.add(token_id)\n",
    "        \n",
    "#             initialization of list of positions, for this document, and for this term\n",
    "            if token_id not in positions_dictionary:\n",
    "                positions_dictionary[token_id] = []\n",
    "#             including current position for positions of this term in this document\n",
    "            positions_dictionary[token_id].append(position)\n",
    "    \n",
    "#     for every word that we are interested, that was found in this document\n",
    "    for token_id in positions_dictionary.keys():\n",
    "#         we update the positional inverted index\n",
    "        positional_inverted_index[token_id][int_doc_id] = positions_dictionary[token_id]\n",
    "        # print('doc:',int_doc_id ,' positions:', positions_dictionary[token_id],' documents :', positional_inverted_index[token_id])\n",
    "\n",
    "#         list of positions of query terms in a document\n",
    "        # positions_of_term_in_document[int_doc_id][token_id] = positions_dictionary[token_id]\n",
    "        \n",
    "\n",
    "    document_lengths[int_doc_id] = document_length\n",
    "    total_terms += document_length\n",
    "\n",
    "    unique_terms_per_document[int_doc_id] = len(document_bow)\n",
    "\n",
    "    for query_term_id in query_term_ids:\n",
    "        assert query_term_id is not None\n",
    "\n",
    "        document_term_frequency = document_bow.get(query_term_id, 0)\n",
    "\n",
    "        if document_term_frequency == 0:\n",
    "            continue\n",
    "\n",
    "        collection_frequencies[query_term_id] += document_term_frequency\n",
    "        inverted_index[query_term_id][int_doc_id] = document_term_frequency\n",
    "\n",
    "avg_doc_length = total_terms / num_documents\n",
    "\n",
    "print('Inverted index creation took', time.time() - start_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trec evaluatation\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "def trec_eval(validation_file,test_file_name):\n",
    "    \"\"\"\n",
    "   returs the evaluation for a given file against a reference file\n",
    "   returns eval for each single query document pair as well as the \n",
    "   overall scores\n",
    "   \n",
    "    \"\"\"\n",
    "    cmd = ['./run_trec_eval.sh',validation_file, test_file_name]\n",
    "    evaluation = {}\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n",
    "    for line in process.stdout:\n",
    "        splits = line.decode().strip().split()\n",
    "        doc_id, query_id, score = splits\n",
    "        if splits[1] in evaluation:\n",
    "            evaluation[query_id].append({doc_id: float(score)})\n",
    "        else:\n",
    "            evaluation[query_id] = [{doc_id:float(score)}]\n",
    "            \n",
    "        process.wait()\n",
    "        \n",
    "    return evaluation\n",
    "\n",
    "validation_data = 'ap_88_89/qrel_validation'\n",
    "test_data = 'ap_88_89/qrel_test'\n",
    "\n",
    "measure_names = ['ndcg_cut_10', 'map_cut_1000', 'P_5', 'recall_1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put scores in the right array structure\n",
    "def restruct(arr, overall=True):\n",
    "    ndcg10 = []\n",
    "    map1000 = []\n",
    "    p5 = []\n",
    "    r1000 = []\n",
    "    if overall:\n",
    "        query_scores = arr['all']\n",
    "        return [query_scores[2][measure_names[0]], query_scores[3][measure_names[1]],query_scores[0][measure_names[2]],query_scores[1][measure_names[3]]]\n",
    "            \n",
    "    for query_id, query_scores in arr.items():\n",
    "        if overall is False and query_id is not 'all':\n",
    "            p5.append(query_scores[0][measure_names[2]])\n",
    "            r1000.append(query_scores[1][measure_names[3]])\n",
    "            ndcg10.append(query_scores[2][measure_names[0]])\n",
    "            map1000.append(query_scores[3][measure_names[1]])\n",
    "    return ndcg10, map1000, p5, r1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculates kl divergence \n",
    "def kl_divergence(query_language_model, document_language_model ):\n",
    "    \"\"\"\n",
    "    calculate kl-divergence \n",
    "    given a language model and a document model\n",
    "    \n",
    "    \"\"\"\n",
    "    return query_language_model * np.log( query_language_model / document_language_model)\n",
    "def calculate_query_lm(document_term_positions,param):\n",
    "    \n",
    "    \"\"\"\n",
    "    calculates the smoothed query language model\n",
    "    return: log p(q|d): score for document generating the query\n",
    "    \"\"\"\n",
    "    \n",
    "     # calculating query language model (unigram)\n",
    "    query_language_model = {}\n",
    "    for query_term,positions in document_term_positions.items():\n",
    "        freq = len(positions)\n",
    "        if query_term not in query_language_model:\n",
    "            query_language_model[query_term] = 0\n",
    "        # add prob for query_term to dict    \n",
    "        query_language_model[query_term] += 1/freq\n",
    "    # calculate background probability\n",
    "    smoothed_query_language_model = {}\n",
    "    for query_term, freq in query_language_model.items():\n",
    "        # background word count\n",
    "        C = collection_frequencies[query_term]\n",
    "        if query_term not in query_language_model:\n",
    "            smoothed_query_language_model[query_term] = 0\n",
    "        # add background probability to dict    \n",
    "        smoothed_query_language_model[query_term] = C/total_terms  \n",
    "    # calculate log(q|d), formula see above\n",
    "    score = 0\n",
    "    for query_term,_ in document_term_freq.items():\n",
    "        score += np.log(query_language_model[query_term]/(param*smoothed_query_language_model[query_term])) +len(document_term_freq) * np.log(param)     \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot for parameter validation\n",
    "def plot_validation(score, params):\n",
    "    # transpose array\n",
    "    plt.plot(params,score, label=measure_names[0])\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('NDCG')\n",
    "    #plt.legend(measure_names,loc=(1.04,0))  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find best parameter by finding the best ndcg score\n",
    "\n",
    "def find_best_param(all_scores, params):\n",
    "    return params[np.argmax(np.array(all_scores))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for every query get id of documents that contain at least one query token\n",
    "doc_list = {}\n",
    "#iterate through queries\n",
    "for query_id, query_tokens in tokenized_queries.items():\n",
    "    accumulate_docs = set()\n",
    "    #iterate through query tokens\n",
    "    for query_token in query_tokens:\n",
    "        # iterate through doc ids that contain at least one word of the query token \n",
    "        for docs in inverted_index[query_token].keys():\n",
    "            # append doc id \n",
    "            accumulate_docs.add(docs)\n",
    "    doc_list[str(query_id)] = accumulate_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average document length:  256.438197537\n"
     ]
    }
   ],
   "source": [
    "# calculate the average lenght of documents\n",
    "av_document_length = np.mean(list(document_lengths.values()))\n",
    "print('Average document length: ',av_document_length)\n",
    "\n",
    "def run_retrieval(model_name, score_fn, param=None):\n",
    "    \"\"\"\n",
    "    Runs a retrieval method for all the queries and writes the TREC-friendly results in a file.\n",
    "    \n",
    "    :param model_name: the name of the model (a string)\n",
    "    :param score_fn: the scoring function (a function - see below for an example) \n",
    "    \"\"\"\n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "    if os.path.exists(run_out_path):\n",
    "        #run_out_path+'_copy'\n",
    "        return\n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    print('Retrieving using', model_name)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # TODO: fill the data dictionary. \n",
    "    # The dictionary data should have the form: query_id --> (document_score, external_doc_id)\n",
    "\n",
    "    # Iterates through queries\n",
    "    for query in queries.items():\n",
    "        query_id, _ = query\n",
    "        print (query_id)\n",
    "        query_term_ids = tokenized_queries[query_id]\n",
    "        scores = []\n",
    "        # Iterate through every token \n",
    "        #for document_id in range(index.document_base(), index.maximum_document()):  \n",
    "        for document_id in doc_list[str(query_id)]: \n",
    "            ex_doc_id, _ = index.document(document_id)\n",
    "\n",
    "            # calculate the score for every document-query pair\n",
    "            score = score_fn(document_id, query_id, positional_inverted_index, param)\n",
    "\n",
    "            # Append score for a specific document \n",
    "            scores.append((score, ex_doc_id))\n",
    "        # Append scores for a query\n",
    "        data[str(query_id)] = scores\n",
    "    print('Retrieval took:', time.time() - retrieval_start_time )\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "We discard the multiplication term that is added for very long queries in our implementation, since there is no value given for k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tfidf(int_document_id, query_id, positional_inverted_index , _ ):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_id: the query id of the query\n",
    "    :param positional_inverted_index: an extended inverted index that also stores the position of the \n",
    "                                            terms on the document\n",
    "    \"\"\"\n",
    "    \n",
    "#     the final score\n",
    "    score = 0\n",
    "#     for every word in the query\n",
    "    for query_token_id in tokenized_queries[query_id]:\n",
    "#         if the query term has been found on the document\n",
    "        if int_document_id in positional_inverted_index[query_token_id]:\n",
    "#         calculating tf\n",
    "            tf = 1 + np.log(   len( positional_inverted_index    [query_token_id][int_document_id]   )  )\n",
    "#         calculating idf\n",
    "            idf  = np.log(num_documents/len(inverted_index[query_token_id]))\n",
    "#        calculating score for this term\n",
    "            score += tf*idf\n",
    "    return score\n",
    "\n",
    "run_retrieval('tfidf', tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "Scores: {'ndcg_cut_10': 0.4254, 'map_cut_1000': 0.22, 'P_5': 0.435, 'recall_1000': 0.6491}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "tfidf_scores = trec_eval(test_data, 'tfidf.run')\n",
    "print(len(tfidf_scores))\n",
    "print('Scores:', dict(zip(measure_names, restruct(tfidf_scores))))\n",
    "tfidf_scores = restruct(tfidf_scores, False)\n",
    "\n",
    "# Scores: {'ndcg_cut_10': 0.4254, 'map_cut_1000': 0.22, 'P_5': 0.435, 'recall_1000': 0.6491}\n",
    "\n",
    "# Scores: {'ndcg_cut_10': 0.4169, 'map_cut_1000': 0.2155, 'P_5': 0.4317, 'recall_1000': 0.651}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25\n",
    "\n",
    "We discard the multiplication term that is added for very long queries in our implementation, since there is no value given for k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BM25(int_document_id, query_id, positional_inverted_index, _ , k1=1.2, b=0.75):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_id: the query id of the query\n",
    "#     :param positional_inverted_index: an extended inverted index that also stores the position of the \n",
    "#                                             terms on the document\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    # Iterate through query terms \n",
    "    for query_token_id in tokenized_queries[query_id]:\n",
    "#         if the query term has been found on the document\n",
    "        if int_document_id in positional_inverted_index[query_token_id]:\n",
    "            # getting number of times this term appeared in this document\n",
    "            count = len( positional_inverted_index    [query_token_id][int_document_id]   )\n",
    "            # getting document length\n",
    "            len_doc = document_lengths[int_document_id]\n",
    "\n",
    "            tf = (((k1 + 1) * count) / ((k1 * ((1-b) + b * (len_doc/av_document_length))) + count)) \n",
    "            idf = np.log(num_documents/len(positional_inverted_index[query_token_id]))\n",
    "            score += tf*idf\n",
    "    return score\n",
    "\n",
    "# run_retrieval('BM25', BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'ndcg_cut_10': 0.4086, 'map_cut_1000': 0.2173, 'P_5': 0.4133, 'recall_1000': 0.6524}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "bm25_scores = trec_eval(test_data, 'BM25.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(bm25_scores))))\n",
    "bm25_scores = restruct(bm25_scores, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "\n",
    "## Jelinek-Mercer \n",
    "\n",
    "Explore different values of ð›Œ in the range [0.1, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def JM(int_document_id, query_id, positional_inverted_index, lamb):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_id: the query id of the query\n",
    "    :param positional_inverted_index: an extended inverted index that also stores the position of the \n",
    "# #                                             terms on the document\n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    # Iterate through query terms \n",
    "    for query_token_id in tokenized_queries[query_id]:\n",
    "#         if the query term has been found on the document\n",
    "        if int_document_id in positional_inverted_index[query_token_id]:\n",
    "#         calculating the document term model p(w|d)\n",
    "            document_term_model =  len(positional_inverted_index [query_token_id][int_document_id]) /document_lengths[int_document_id]\n",
    "        else:\n",
    "            document_term_model = 0\n",
    "#         calculating the corpus term model  p(w|C)\n",
    "        corpus_term_model = collection_frequencies[query_token_id] / total_terms\n",
    "        prob = lamb* document_term_model  + (1.-lamb)* corpus_term_model\n",
    "        score += np.log(prob)\n",
    "    return score\n",
    "\n",
    "lambdas = [0.1,0.5,0.9]\n",
    "\n",
    "# for lamb in lambdas:\n",
    "#     run_retrieval('JM_'+str(lamb), JM, lamb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3676]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGvJJREFUeJzt3X2wX3Vh5/H3h4QopMSnXHeUkE2g\nl7GpwSg/I3YFXAQaigNYywikGB9201AinfoEjnSnRtvpUmVa11QWGUCsIVO11uyKxIcVdqHsNDcY\nEkBjHqRwCVsCZEzEhyTw2T/ON3Jyc3N/N/fk3JubfF4zv7nn+3C+v+85c3M/Oef8fufINhERESN1\n1FhPICIixrcESURENJIgiYiIRhIkERHRSIIkIiIaSZBEREQjCZKIiGgkQRIREY0kSCIiopGJYz2B\n0TB16lTPmDFjrKcRETFuTJ06lZUrV660Pa9b3yMiSGbMmEFfX99YTyMiYlyRNHU4/XJqKyIiGkmQ\nREREIwmSiIhoJEESERGNJEgiIqKRBElERDSSIImIiEYSJBER0UiCJCIiGkmQREREI60GiaR5ktZL\n2ijpmkHaF0laJ2mNpHskzSr1R0v6Ymn7oaSP1dZ5pLZO7nsSETHGWrvXlqQJwFLgHKAfWCVphe2H\na92W2b6h9L8AuB6YB1wMvMj2bEnHAg9Lut32I2W9/2j7qbbmHhERw9fmEclcYKPtzbZ3AsuBC+sd\nbG+vFScD3tMETJY0ETgG2AnU+0ZExCGizSA5HnisVu4vdXuRdKWkTcB1wFWl+qvAs8ATwKPAp20/\nU9oMfFvSakkL25p8REQMT5tBokHqvE+FvdT2ScDVwLWlei7wHPBqYCbwIUknlrb/YPsNwHnAlZLO\nGPTNpYWS+iT1bd26teGmRETE/rQZJP3ACbXyNGDLEP2XAxeV5cuAO23vsv0kcC/QAbC9pfx8Evg6\nVejsw/aNtju2Oz09PY02JCIi9q/NIFkF9EqaKWkScAmwot5BUm+teD6woSw/CpylymTgNOBHkiZL\nOq6sOxk4F3iwxW2IiIguWvvUlu3dkhYDK4EJwM22H5K0BOizvQJYLOlsYBewDVhQVl8K3EIVEgJu\nsb22nN76uqQ9c19m+862tiEiIrqTvc9li8NOp9NxHrUbEXFgJK223enWL99sj4iIRhIkERHRSIIk\nIiIaSZBEREQjCZKIiGgkQRIREY0kSCIiopEESURENJIgiYiIRhIkERHRSIIkIiIaSZBEREQjCZKI\niGgkQRIREY0kSCIiopEESURENJIgiYiIRhIkERHRSKtBImmepPWSNkq6ZpD2RZLWSVoj6R5Js0r9\n0ZK+WNp+KOljwx0zIiJGV2tBImkCsBQ4D5gFXLonKGqW2Z5tew5wHXB9qb8YeJHt2cCpwB9JmjHM\nMSMiYhS1eUQyF9hoe7PtncBy4MJ6B9vba8XJgPc0AZMlTQSOAXYC24czZkREjK42g+R44LFaub/U\n7UXSlZI2UR2RXFWqvwo8CzwBPAp82vYzwx2zjLtQUp+kvq1btzbdloiI2I82g0SD1HmfCnup7ZOA\nq4FrS/Vc4Dng1cBM4EOSThzumGXcG213bHd6enpGMv+IiBiGNoOkHzihVp4GbBmi/3LgorJ8GXCn\n7V22nwTuBTojGDMiIlrWZpCsAnolzZQ0CbgEWFHvIKm3Vjwf2FCWHwXOUmUycBrwo+GMGRERo2ti\nWwPb3i1pMbASmADcbPshSUuAPtsrgMWSzgZ2AduABWX1pcAtwINUp7Nusb0WYLAx29qGiIjoTvag\nlxgOK51Ox319fWM9jYiIcUXSatudbv3yzfaIiGgkQRIREY0kSCIiopEESURENJIgiYiIRhIkERHR\nSIIkIiIaSZBEREQjCZKIiGgkQRIREY0kSCIiopEESURENJIgiYiIRhIkERHRSIIkIiIaSZBEREQj\nCZKIiGgkQRIREY20GiSS5klaL2mjpGsGaV8kaZ2kNZLukTSr1M8vdXtez0uaU9ruKmPuaXtlm9sQ\nERFDm9jWwJImAEuBc4B+YJWkFbYfrnVbZvuG0v8C4Hpgnu0vA18u9bOBb9heU1tvvu08hD0i4hDQ\n5hHJXGCj7c22dwLLgQvrHWxvrxUnAx5knEuB21ubZURENNLaEQlwPPBYrdwPvGlgJ0lXAh8EJgFn\nDTLOuxgQQMAtkp4DvgZ8yvY+ASRpIbAQYPr06SOZf0REDEObRyQapG6fP/i2l9o+CbgauHavAaQ3\nAT+3/WCter7t2cDp5XX5YG9u+0bbHdudnp6ekW5DRER00WaQ9AMn1MrTgC1D9F8OXDSg7hIGnNay\n/Xj5uQNYRnUKLSIixkibQbIK6JU0U9IkqlBYUe8gqbdWPB/YUGs7CriYKmD21E2UNLUsHw28Hagf\nrURExChr7RqJ7d2SFgMrgQnAzbYfkrQE6LO9Algs6WxgF7ANWFAb4gyg3/bmWt2LgJUlRCYA3wW+\n0NY2REREdxrkOvVhp9PpuK8vnxaOiDgQklbb7nTrl2+2R0REIwmSiIhoJEESERGNJEgiIqKRBElE\nRDSSIImIiEYSJBER0UiCJCIiGkmQREREIwmSiIhoJEESERGNJEgiIqKRBElERDSSIImIiEYSJBER\n0UiCJCIiGkmQREREIwmSiIhopNUgkTRP0npJGyVdM0j7IknrJK2RdI+kWaV+fqnb83pe0pzSdmpZ\nZ6Okz0pSm9sQERFDay1IJE0AlgLnAbOAS/cERc0y27NtzwGuA64HsP1l23NK/eXAI7bXlHU+DywE\nestrXlvbEBER3bV5RDIX2Gh7s+2dwHLgwnoH29trxcmABxnnUuB2AEmvAqbYvs+2gduAi9qYfERE\nDM/EFsc+HnisVu4H3jSwk6QrgQ8Ck4CzBhnnXbwQQMeXcepjHj/Ym0taSHXkwvTp0w9w6hERMVxD\nHpFIer+kj9TKj0vaLmmHpCu6jD3YtYt9jjhsL7V9EnA1cO2A938T8HPbDx7ImGXcG213bHd6enq6\nTDUiIkaq26mtRcDNtfKTtqcAPVSnnIbSD5xQK08DtgzRfzn7nqa6hHJaqzbmtAMYMyIiWtYtSI6y\n/XSt/BUA278Ejumy7iqgV9JMSZOoQmFFvYOk3lrxfGBDre0o4GKqgKG87xPADkmnlU9rvRv4Rpd5\nREREi7pdI3lJvWD7L+HXf+RfMdSKtndLWgysBCYAN9t+SNISoM/2CmCxpLOBXcA2YEFtiDOAftub\nBwx9BXArVZB9q7wiImKMqPrw034apb8DnrE98NrFp4Cpthe1PL+DotPpuK+vb6ynERExrkhabbvT\nrV+3I5KPADdJ2gg8UOpeB/QB/6nZFCMi4nAwZJDYfpbqi4QnAr9dqh+2van1mUVExLgwZJBI+l3g\nONtfBTbX6udTfYLrOy3PLyIiDnHdPrX1CeDuQeq/Byw5+NOJiIjxpluQHGt768BK2/+P6pYmERFx\nhOsWJC+WtM/pL0lH0/17JBERcQToFiT/CHxB0q+PPsryDaUtIiKOcN2C5Frg34B/lbRa0v3AI8BW\nBtwXKyIijkzdPv67G7hG0ieA3yzVG23/ovWZRUTEuND1NvKSXgFcBrymVP1Q0u0D7sEVERFHqG63\nkf8t4EHgVODHVDdVfCOwTtJrhlo3IiKODN2OSD4J/Intf6hXSnon8BfAO9uaWEREjA/dLrbPHhgi\nALa/Bry2nSlFRMR40i1Inh1hW0REHCG6ndp6paQPDlIvqqckRkTEEa5bkHwBOG4/bTcd5LlERMQ4\n1O17JJ8YrYlERMT41O028v9liGbb/mSX9ecBf0v1qN2bbP/VgPZFwJXAc8DPgIW2Hy5tpwD/HZgC\nPA+80fYvJd0FvArY86XIc20/OdQ8IiKiPd1ObQ12QX0y8H6qZ7bvN0gkTQCWAucA/cAqSSv2BEWx\nzPYNpf8FwPXAvHKjyL8HLrf9QPlS5K7aevNt59m5ERGHgG6ntj6zZ1nSccCfAO8FlgOf2d96xVyq\n26lsLusvBy4Efh0ktrfX+k8G9jxA/lxgre0HSr98iz4i4hDV7eO/SHq5pE8Ba6mC5w22rx7G6aTj\ngcdq5f5SN3D8KyVtAq4DrirVJwOWtFLS/ZI+OmC1WyStkfRnktRtGyIioj3dbpHy18AqYAfVlxP/\n3Pa2YY492B9471NhL7V9EnA1L9xReCLwFmB++fkOSW8rbfNtzwZOL6/L9zP3hZL6JPVt3brPs7ki\nIuIg6XZE8iHg1VR/4LdI2l5eOyRt77JuP3BCrTwN2DJE/+XARbV177b9lO2fA3cAbwCw/Xj5uQNY\nRnUKbR+2b7Tdsd3p6clXXiIi2jJkkNg+yvYxto+zPaX2Os72lC5jrwJ6Jc2UNAm4BFhR7yCpt1Y8\nn+qmkAArgVMkHVsuvJ8JPCxpoqSpZd2jgbdT3VQyIiLGSNfbyI+U7d2SFlOFwgTgZtsPSVoC9Nle\nASyWdDbVJ7K2AQvKutskXU8VRgbusP3N8nTGlSVEJgDfpfrSZEREjBHZ+1y2OOx0Oh339eXTwhER\nB0LSatudbv26fmorIiJiKAmSiIhoJEESERGNJEgiIqKRBElERDSSIImIiEYSJBER0UiCJCIiGkmQ\nREREIwmSiIhoJEESERGNJEgiIqKRBElERDSSIImIiEYSJBER0UiCJCIiGkmQREREIwmSiIhopNUg\nkTRP0npJGyVdM0j7IknrJK2RdI+kWbW2UyTdJ+mh0ufFpf7UUt4o6bOS1OY2RETE0FoLEkkTgKXA\necAs4NJ6UBTLbM+2PQe4Dri+rDsR+Htgke3fBt4K7CrrfB5YCPSW17y2tiEiIrpr84hkLrDR9mbb\nO4HlwIX1Dra314qTAZflc4G1th8o/Z62/ZykVwFTbN9n28BtwEUtbkNERHTRZpAcDzxWK/eXur1I\nulLSJqojkqtK9cmAJa2UdL+kj9bG7O82ZkREjJ42g2Swaxfep8Jeavsk4Grg2lI9EXgLML/8fIek\ntw13TABJCyX1SerbunXrSOYfERHD0GaQ9AMn1MrTgC1D9F/OC6ep+oG7bT9l++fAHcAbSv204Yxp\n+0bbHdudnp6eEW5CRER002aQrAJ6Jc2UNAm4BFhR7yCpt1Y8H9hQllcCp0g6tlx4PxN42PYTwA5J\np5VPa70b+EaL2xAREV1MbGtg27slLaYKhQnAzbYfkrQE6LO9Algs6WyqT2RtAxaUdbdJup4qjAzc\nYfubZegrgFuBY4BvlVdERIwRVR9+Orx1Oh339fWN9TQiIsYVSattd7r1yzfbIyKikQRJREQ0kiCJ\niIhGEiQREdFIgiQiIhpJkERERCMJkoiIaCRBEhERjSRIIiKikQRJREQ0kiCJiIhGEiQREdFIgiQi\nIhpJkERERCMJkoiIaCRBEhERjSRIIiKikQRJREQ00mqQSJonab2kjZKuGaR9kaR1ktZIukfSrFI/\nQ9IvSv0aSTfU1rmrjLmn7ZVtbkNERAxtYlsDS5oALAXOAfqBVZJW2H641m2Z7RtK/wuA64F5pW2T\n7Tn7GX6+7TyEPSLiENDmEclcYKPtzbZ3AsuBC+sdbG+vFScDbnE+ERHRgjaD5HjgsVq5v9TtRdKV\nkjYB1wFX1ZpmSvqBpLslnT5gtVvKaa0/k6SDPvOIiBi2NoNksD/w+xxx2F5q+yTgauDaUv0EMN32\n64EPAsskTSlt823PBk4vr8sHfXNpoaQ+SX1bt25tuCkREbE/bQZJP3BCrTwN2DJE/+XARQC2f2X7\n6bK8GtgEnFzKj5efO4BlVKfQ9mH7Rtsd252enp6GmxIREfvTZpCsAnolzZQ0CbgEWFHvIKm3Vjwf\n2FDqe8rFeiSdCPQCmyVNlDS11B8NvB14sMVtiIiILlr71Jbt3ZIWAyuBCcDNth+StATos70CWCzp\nbGAXsA1YUFY/A1giaTfwHLDI9jOSJgMrS4hMAL4LfKGtbYiIiO5kH/4flOp0Ou7ry6eFIyIOhKTV\ntjvd+uWb7RER0UiCJCIiGkmQREREIwmSiIhoJEESERGNJEgiIqKRBElERDSSIImIiEYSJBER0UiC\nJCIiGkmQREREIwmSiIhoJEESERGNJEgiIqKRBElERDSSIImIiEYSJBER0UiCJCIiGmk1SCTNk7Re\n0kZJ1wzSvkjSOklrJN0jaVapnyHpF6V+jaQbauucWtbZKOmzktTmNkRExNBaCxJJE4ClwHnALODS\nPUFRs8z2bNtzgOuA62ttm2zPKa9FtfrPAwuB3vKa19Y2REREd20ekcwFNtrebHsnsBy4sN7B9vZa\ncTLgoQaU9Cpgiu37bBu4Dbjo4E47IiIORJtBcjzwWK3cX+r2IulKSZuojkiuqjXNlPQDSXdLOr02\nZn+3MSMiYvS0GSSDXbvY54jD9lLbJwFXA9eW6ieA6bZfD3wQWCZpynDHBJC0UFKfpL6tW7eOaAMi\nIqK7NoOkHzihVp4GbBmi/3LKaSrbv7L9dFleDWwCTi5jThvOmLZvtN2x3enp6RnxRkRExNDaDJJV\nQK+kmZImAZcAK+odJPXWiucDG0p9T7lYj6QTqS6qb7b9BLBD0mnl01rvBr7R4jZEREQXE9sa2PZu\nSYuBlcAE4GbbD0laAvTZXgEslnQ2sAvYBiwoq58BLJG0G3gOWGT7mdJ2BXArcAzwrfKKiIgxourD\nT4e3Tqfjvr6+sZ5GRMS4Imm17U63fvlme0RENJIgiYiIRhIkERHRSIIkIiIaSZBEREQjCZKIiGgk\nQRIREY0kSCIiopEESURENHJEfLNd0lbgX8dwClOBp8bw/Q8l2Rd7y/7YW/bHC8Z6XzwFYLvrwwOP\niCAZa5L6hnObgSNB9sXesj/2lv3xgvG0L3JqKyIiGkmQREREIwmS0XHjWE/gEJJ9sbfsj71lf7xg\n3OyLXCOJiIhGckQSERGNJEgakDRP0npJGyVdM0j7dEnfl/QDSWsl/V6t7RRJ90l6SNI6SS8e3dkf\nfCPdH5KOlvTFsh9+KOljoz/7g28Y++PfS/pe2Rd3SZpWa1sgaUN5LRi47ngz0n0haU7t38laSe8a\n/dkffE1+N0r7FEmPS/rc6M16CLbzGsGL6vHBm4ATgUnAA8CsAX1uBK4oy7OAR8ryRGAt8LpSfgUw\nYay3aQz3x2XA8rJ8LPAIMGOst2kU9sdXgAVl+SzgS2X55cDm8vNlZfllY71NY7QvTgZ6y/KrgSeA\nl471No3V/qi1/y2wDPjcWG+P7RyRNDAX2Gh7s+2dwHLgwgF9DEwpyy8BtpTlc4G1th8AsP207edG\nYc5tarI/DEyWNBE4BtgJbG9/yq0azv6YBXyvLH+/1v67wHdsP2N7G/AdoOuXwg5hI94Xtn9se0NZ\n3gI8CfSMyqzb0+R3A0mnAv8O+PYozHVYEiQjdzzwWK3cX+rq/hz4Q0n9wB3AB0r9yYAlrZR0v6SP\ntj3ZUdBkf3wVeJbqf5uPAp+2/Uyrs23fcPbHA8A7y/I7gOMkvWKY644nTfbFr0maS/U/+E0tzXO0\njHh/SDoK+AzwkdZneQASJCOnQeoGfgTuUuBW29OA3wO+VH4RJgJvAeaXn++Q9LY2JzsKmuyPucBz\nVKcuZgIfknRim5MdBcPZHx8GzpT0A+BM4HFg9zDXHU+a7ItqAOlVwJeA99p+vq2JjpIm++OPgTts\nP8YhZOJYT2Ac6wdOqJWn8cKpmj3eTzklYfu+ckF9aln3bttPAUi6A3gDLxzKjkdN9sdlwJ22dwFP\nSroX6FBdGxivuu6Pcqrm9wEk/QbwTts/LUdsbx2w7l1tTrZlI94XpTwF+CZwre3/OyozbleT3403\nA6dL+mPgN4BJkn5me58L9qMpRyQjtwrolTRT0iTgEmDFgD6PAm8DkPRbwIuBrcBK4BRJx5brAmcC\nD4/azNvRZH88CpylymTgNOBHozbzdnTdH5KmliMygI8BN5fllcC5kl4m6WVU19RWjtK82zDifVH6\nfx24zfZXRnHObRrx/rA93/Z02zOojlpuG+sQAfKprSYvqtMzP6Y6Z/vxUrcEuKAszwLupTrfuQY4\nt7buHwIPAQ8C1431tozl/qD6n9VXyv54GPjIWG/LKO2PPwA2lD43AS+qrfs+YGN5vXest2Ws9kX5\nd7Kr/L7sec0Z6+0Zy9+N2hjv4RD51Fa+2R4REY3k1FZERDSSIImIiEYSJBER0UiCJCIiGkmQRERE\nIwmSOCxJ+tmA8nsOmTuljjFJMyRdNtbziMNHgiTiIChfLD2Y4004mOMNMIPqbgLD1vJ8YpxLkMQR\nRdJxkn4i6ehSniLpkfJMlLsk/Y2kf5b0YLlJIJImS7pZ0ipVz1K5sNS/R9JXJP0PBrkTq6RbJd0g\n6f9I+rGkt5f6GaXu/vL6nVL/VlXPa1kGrCt1/yRpdXkex8La2D+T9F9L23clzS3z3yzpgtJngqS/\nLvNeK+mPyup/RXWbjTWS/nR//QabT8Rgcq+tOFwdI2lNrfxyYIXtHZLuAs4H/onq9hRfs71LEsBk\n278j6Qyq21K8Fvg48L9sv0/SS4F/kfTdMu6bgVO8/7sVz6C6Bc5JwPcl/SbVrdDPsf1LSb3A7VT3\nFoPqBpavtf2TUn6f7WckHQOskvQ1208Dk4G7bF8t6evAp4BzqO4e8EWqW268H/ip7TdKehFwr6Rv\nA9cAH7a9J9gW7qffYPOJ2EeCJA5Xv7A9Z09B0nt44Y/1TcBHqYLkvcB/rq13O4Dt/12OVl5Kda+r\nCyR9uPR5MTC9LH9niBAB+AdXd6vdIGkz8BrgJ8DnJM2huuvxybX+/zLgj/ZVkt5Rlk8AeoGnqZ7Z\ncmepXwf8qoThOqrwosz7FEl/UMovKevvHDDHofoNnE/EPhIkccSxfW85vXQm1ZMpH6w3D+xOddvv\nd9peX2+Q9Caq56jsKf8F1ZEOtRAbbLw/Bf4NeB3V6eVf1trr470VOBt4s+2flyOpPY9k3uUX7m/0\nPPCr8r7P167XCPiA7b1u+FjG3atqiH7PEtFFrpHEkeo2qqOPWwbUvwtA0luoTvf8lOrOux9QOfcl\n6fWDDWj747bn1I+EgIslHSXpJKpHq66n+h//E+VI5XKqR68O5iXAthIir6G6K/KBWAlcUbsedLKq\nuyvvAI4bRr+IYckRSRypvkx1XeH2AfXbJP0z1SOB31fqPgn8DbC2hMkjwNuH+T7rgbupHo26qFwX\n+Tvga5IupnqM6v7+138nsEjS2jLOgT6L4yaq01z3l3lvBS4C1gK7JT0A3Er1/O/B+kUMS+7+G0ek\ncj3gQtuX1+ruoroI3XeQ3uNW4H/a/urBGC/iUJUjkjjiSPpvwHlUz4SIiIZyRBIREY3kYntERDSS\nIImIiEYSJBER0UiCJCIiGkmQREREIwmSiIho5P8DtVxXLSmz8/EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x150fadef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper param 0.9\n",
      "Scores: {'ndcg_cut_10': 0.3744, 'map_cut_1000': 0.1929, 'P_5': 0.3733, 'recall_1000': 0.6212}\n"
     ]
    }
   ],
   "source": [
    "# run evaluation for different lambdas on validation data\n",
    "# change array stracture in a suitabale way for us\n",
    "JM_val_scores = [restruct(trec_eval(validation_data, 'JM_'+str(lamb)+'.run'))[0] for lamb in lambdas]\n",
    "print(JM_val_scores)\n",
    "# plot overall scores for all measures\n",
    "plot_validation(JM_val_scores, lambdas)\n",
    "# get best parameter by NDCG\n",
    "best_param_JM = find_best_param(JM_val_scores,lambdas )\n",
    "print('Best hyper param', best_param_JM)\n",
    "# run evaluation for different lambdas on test data\n",
    "JM_scores = trec_eval(test_data, 'JM_'+str(best_param_JM)+'.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(JM_scores))))\n",
    "JM_scores = restruct(JM_scores, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirichlet Prior \n",
    "\n",
    "Explore different values of ð› [500, 1000, 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DP(int_document_id, query_id, positional_inverted_index, mu):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_id: the query id of the query\n",
    "    :param positional_inverted_index: an extended inverted index that also stores the position of the \n",
    "# #                                             terms on the document\n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    len_doc = document_lengths[int_document_id]\n",
    "    \n",
    "#     some documents do not contain any words, so their score is obviously 0\n",
    "    if len_doc == 0:\n",
    "        return - float('inf')\n",
    "    \n",
    "    # Iterate through query terms \n",
    "    for query_token_id in tokenized_queries[query_id]:\n",
    "#         if the query term has been found on the document\n",
    "        if int_document_id in positional_inverted_index[query_token_id]:\n",
    "#         calculating the document term model p(w|d)\n",
    "            document_term_model =  len(positional_inverted_index [query_token_id][int_document_id]) / len_doc\n",
    "        else:\n",
    "            document_term_model = 0\n",
    "#         calculating the corpus term model  p(w|C)\n",
    "        corpus_term_model = collection_frequencies[query_token_id] / total_terms\n",
    "    \n",
    "        prob = ((len_doc/(len_doc + mu)) * document_term_model) + (mu/(mu+ len_doc)) * corpus_term_model\n",
    "        score += np.log(prob)\n",
    "    return score\n",
    "\n",
    "# mus = [500,1000,1500]\n",
    "\n",
    "# for mu in mus:\n",
    "#     run_retrieval('DP_'+str(mu), DP, mu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4026]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEKCAYAAAAxXHOuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKiUQmWiIhoVIIlIiIa9f8BblUJKarNk7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1328fa7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper param 1500\n",
      "Scores: {'ndcg_cut_10': 0.4111, 'map_cut_1000': 0.2139, 'P_5': 0.405, 'recall_1000': 0.6367}\n"
     ]
    }
   ],
   "source": [
    "# run evaluation for different lambdas on validation data\n",
    "# change array stracture in a suitabale way for us\n",
    "DP_val_scores = [restruct(trec_eval(validation_data, 'DP_'+str(mu)+'.run'))[0] for mu in mus]\n",
    "print(DP_val_scores)\n",
    "# plot overall scores for all measures\n",
    "plot_validation(DP_val_scores, mus)\n",
    "# get best parameter by NDCG\n",
    "best_param_DP = find_best_param(DP_val_scores,mus)\n",
    "print('Best hyper param', best_param_DP)\n",
    "# run evaluation for different lambdas on test data\n",
    "DP_scores = trec_eval(test_data, 'DP_'+str(best_param_DP)+'.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(DP_scores))))\n",
    "DP_scores = restruct(DP_scores, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute discount smoothing\n",
    "\n",
    "Explore different values of ð›… in the range [0.1, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ADS(int_document_id, query_id, positional_inverted_index, delta=0.1):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_id: the query id of the query\n",
    "    :param positional_inverted_index: an extended inverted index that also stores the position of the \n",
    "# #                                             terms on the document\n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    len_doc = document_lengths[int_document_id]\n",
    "    \n",
    "#     some documents do not contain any words, so their score is obviously 0\n",
    "    if len_doc == 0:\n",
    "        return - float('inf')\n",
    "    \n",
    "    # Iterate through query terms \n",
    "    for query_token_id in tokenized_queries[query_id]:\n",
    "#         if the query term has been found on the document\n",
    "        if int_document_id in positional_inverted_index[query_token_id]:\n",
    "#         calculating the document term model p(w|d)\n",
    "            document_term_model = len(positional_inverted_index [query_token_id][int_document_id])/len_doc\n",
    "        else:\n",
    "            document_term_model = 0\n",
    "        \n",
    "        C = collection_frequencies[query_token_id]\n",
    "        \n",
    "        prob = document_term_model + (delta* unique_terms_per_document[int_document_id]/len_doc) * (C/total_terms)\n",
    "        score += np.log(prob)\n",
    "    return score\n",
    "\n",
    "# deltas = [0.1,0.5, 0.9]\n",
    "# for delta in deltas:\n",
    "#     run_retrieval('ADS_'+str(delta), ADS, delta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGkmQREREI/8fqEsIqvq4HGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x153cc2dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper param 0.9\n",
      "Scores: {'ndcg_cut_10': 0.3821, 'map_cut_1000': 0.1949, 'P_5': 0.37, 'recall_1000': 0.62}\n"
     ]
    }
   ],
   "source": [
    "# run evaluation for different lambdas on validation data\n",
    "# change array stracture in a suitabale way for us\n",
    "ADS_val_scores = [restruct(trec_eval(validation_data, 'ADS_'+str(delta)+'.run'))[0] for delta in deltas]\n",
    "# plot overall scores for all measures\n",
    "plot_validation(ADS_val_scores, deltas)\n",
    "# get best parameter by NDCG\n",
    "best_param_ADS = find_best_param(ADS_val_scores,deltas )\n",
    "print('Best hyper param', best_param_ADS)\n",
    "# run evaluation for different lambdas on test data\n",
    "ADS_scores = trec_eval(test_data, 'ADS_'+str(best_param_ADS)+'.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(ADS_scores))))\n",
    "ADS_scores = restruct(ADS_scores, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Implementing results of kernels depending on distance for means of reduced complexity\n",
    "def gaussian_kernel(sigma=50):\n",
    "    k = np.zeros(sigma+1)\n",
    "    for i in range(sigma+1):\n",
    "        k[i] = np.exp( (- (i)**2) / (2*sigma**2))\n",
    "    return k\n",
    "\n",
    "def triangle_kernel(sigma=50):\n",
    "    k = np.zeros(sigma+1)\n",
    "    for i in range(sigma+1):\n",
    "        k[i] = 1 - (i/sigma)\n",
    "    return k\n",
    "\n",
    "def cosine_kernel(sigma=50):\n",
    "    k = np.zeros(sigma+1)\n",
    "    for i in range(sigma+1):\n",
    "        k[i] = 1/2 *(1 + np.cos(i*np.pi/sigma))\n",
    "    return k\n",
    "\n",
    "def circle_kernel(sigma=50):\n",
    "    k = np.zeros(sigma+1)\n",
    "    for i in range(sigma+1):\n",
    "        k[i] = np.sqrt(1 - (i/sigma)**2)  \n",
    "    return k\n",
    "\n",
    "def passage_kernel(sigma=50):\n",
    "    k = np.ones(sigma+1)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def PLM(int_document_id, query_id, positional_inverted_index, params):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_id: the query id of the query\n",
    "    :param positional_inverted_index: an extended inverted index that also stores the position of the \n",
    "# #                                             terms on the document\n",
    "    \"\"\"\n",
    "    \n",
    "#     variance for kernel functions\n",
    "    sigma = 50\n",
    "    \n",
    "    mu = params // 1\n",
    "    \n",
    "    print('mu:',mu,', sigma:',sigma)\n",
    "    \n",
    "    kernel_pointer  = params % 1\n",
    "    \n",
    "    if kernel_pointer == 0 :\n",
    "        kernel = gaussian_kernel\n",
    "    elif kernel_pointer == 1 :\n",
    "        kernel = triangle_kernel\n",
    "    elif kernel_pointer == 2 :\n",
    "        kernel = cosine_kernel\n",
    "    elif kernel_pointer == 3 :\n",
    "        kernel = circle_kernel\n",
    "    else:\n",
    "        kernel = passage_kernel\n",
    "    # array with precalculated kernel values, where the index is equal to the distance |i - j|\n",
    "    k = kernel(sigma)\n",
    "    \n",
    "    # storing the tokens of the query because we will need them many times\n",
    "    tokenized_query = tokenized_queries[query_id]\n",
    "\n",
    "#     calculate the maximum position where a query term appears in the document,\n",
    "#     There is no reason to calculate position scores after this value because Best Position Strategy will be used\n",
    "    max_position = 0\n",
    "    # for every query term\n",
    "    for query_token_id in tokenized_query:\n",
    "        # for every appearance of this term in this document\n",
    "        for positions in positional_inverted_index[query_token_id][int_document_id]:\n",
    "            temp_max = max(positions)\n",
    "            if temp_max > max_position :\n",
    "                max_position = temp_max\n",
    "        \n",
    "#     There are cases where the only match with the document is on the first word ( position 0 )\n",
    "    max_position += 1\n",
    "            \n",
    "#     Considering that the PLM-Based Document Ranking will be implemented using Best Position Strategy , \n",
    "#     The best position will be lower or equal to the max position where a term of the query was found in the document\n",
    "    \n",
    "    virtual_document = {}\n",
    "    score = 0\n",
    "    # len_doc = document_lengths[int_document_id]\n",
    "    # Iterate through query terms \n",
    "    for query_token_id in tokenized_query:\n",
    "        \n",
    "#       initialize the virtual document with zero appearances of this word\n",
    "#       sum up to the total propagated count of term word_id at position i\n",
    "#       virtual_document is the :  c'(w,i)\n",
    "        virtual_document[query_token_id] = np.zeros(max_position)\n",
    "        \n",
    "#         if the query term has been found on the document\n",
    "        if int_document_id in positional_inverted_index[query_token_id]:\n",
    "\n",
    "    #         for every term appearance in the document\n",
    "            for j in positional_inverted_index[query_token_id][int_document_id]:\n",
    "    #         left side :\n",
    "    #           if all 50 values of the kernel will be used\n",
    "                limit = sigma +1\n",
    "    #           if less than 50 values of the kernel will be used\n",
    "                if j < sigma:\n",
    "                    limit = j+1\n",
    "                for i in range(limit):\n",
    "                        virtual_document[query_token_id][j-i] += k[i]\n",
    "\n",
    "    #         right side :\n",
    "    #           if all 50 values of the kernel will be used\n",
    "                limit = sigma +1\n",
    "    #           ( again we do not care for score values, for positions greater than max_position,\n",
    "    #             because Best Position Strategy will be used for final scoring of document)\n",
    "    #           if less than 50 values of the kernel will be used\n",
    "                if max_position - j  <= sigma :\n",
    "                    limit = max_position - j\n",
    "                    # here the range will be starting from value 1 so that in position j the kernel will not be added twice\n",
    "                for i in range(1,limit):\n",
    "                        virtual_document[query_token_id][j+i] += k[i]\n",
    "                    \n",
    "\n",
    "#     calculating the length of the virtual document at all positions\n",
    "    Z = np.zeros(max_position)\n",
    "#     for every word included in the query, add all propagated counts, position wise\n",
    "    for query_token_id in tokenized_query:\n",
    "        Z += virtual_document[query_token_id]\n",
    "\n",
    "    \n",
    "#     calculating normalized language model per word\n",
    "#     p_mu (w|D) (Words contributing equally)\n",
    "    normalized_document_language_model = {}\n",
    "    for query_token_id in tokenized_query:\n",
    "        C = collection_frequencies[query_token_id]\n",
    "        \n",
    "        normalized_document_language_model[query_token_id] = (virtual_document[query_token_id] + mu*(C/total_terms))/ (Z + mu)\n",
    "        \n",
    "#   p(w|Q)\n",
    "    query_language_model = {}\n",
    "#     calculating as unigram model\n",
    "    for query_token_id in tokenized_query:\n",
    "#         initializing value\n",
    "        if query_token_id not in query_language_model:\n",
    "            query_language_model[query_token_id] = 0\n",
    "#         adding value to unigram model\n",
    "        query_language_model[query_token_id] += 1/len(tokenized_query)\n",
    "        \n",
    "    scores = np.zeros(max_position)\n",
    "#     calculating final score for all positions\n",
    "    for query_token_id in tokenized_query:\n",
    "        scores += query_language_model[query_token_id] *np.log(query_language_model[query_token_id] / normalized_document_language_model[query_token_id])\n",
    "    scores = - scores\n",
    "        \n",
    "        \n",
    "#     print('query id:',query_term_id, ', doc_id:',int_document_id,scores.shape, document_term_positions)\n",
    "#    returning only the maximum score because Best Position Strategy is being used\n",
    "    return np.max(scores)\n",
    "\n",
    "run_retrieval('PLM', PLM, 500.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run evaluation for different lambdas on validation data\n",
    "# change array stracture in a suitabale way for us\n",
    "PLM_val_scores = collection.defaultdict(list)\n",
    "mus = []\n",
    "for mu in mus:\n",
    "    for kernel_choises in kernel_pointers:\n",
    "#         get a list of scores for the 4 measures  'measure_names'\n",
    "        score = restruct(trec_eval(validation_data, 'PLM_doc_wise_'+ kernel_names[kernel_choises] + '_' + str(mu))\n",
    "#         choose one score\n",
    "        assert('Done' = True) 'choose a score!'\n",
    "                         \n",
    "        PLM_val_scores[str(kernel_names[kernel_choises])].append((mu, score))\n",
    "        \n",
    "                         \n",
    "#  find max for mu\n",
    "#best_param = \n",
    "# plot         \n",
    "\n",
    "\n",
    "print('Best hyper param', best_param)\n",
    "# run evaluation for different lambdas on test data\n",
    "PLM_scores = trec_eval(test_data, 'PLM_'+'_'+str(best_param)+'.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(PLM_scores))))\n",
    "PLM_scores = restruct(PLM_scores, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def compute_ttest(scoresA, scoresB):\n",
    "    # use sediac \n",
    "    alpha = 0.05\n",
    "    comparisons = 4\n",
    "    alpha = 1 - (1 - alpha)**(1./4.)\n",
    "    for i in range(comparisons):\n",
    "        _, p = stats.ttest_rel(scoresA[i],scoresB[i])\n",
    "        if p < alpha:\n",
    "            print('H0 rejected for', measure_names[i])\n",
    "        else:\n",
    "            print('H0 accepted for', measure_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare TF-IDF with BM25:\n",
    "print('Compare TF-IDF with BM25')\n",
    "compute_ttest(tfidf_scores, bm25_scores)\n",
    "print('Compare TF-IDF with best Jelinek-Mercer')\n",
    "compute_ttest(tfidf_scores, JM_scores)\n",
    "print('Compare TF-IDF with best Dirichlet Prior')\n",
    "compute_ttest(tfidf_scores, DP_scores)\n",
    "print('Compare TF-IDF with best ADS')\n",
    "compute_ttest(tfidf_scores, ADS_scores)\n",
    "print('Compare TF-IDF with best PLM')\n",
    "compute_ttest(tfidf_scores, PLM_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Latent Semantic Models (LSMs) [20 points] ###\n",
    "\n",
    "In this task you will experiment with applying distributional semantics methods ([LSI](http://lsa3.colorado.edu/papers/JASIS.lsi.90.pdf) **[5 points]** and [LDA](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf) **[5 points]**) for retrieval.\n",
    "\n",
    "You do not need to implement LSI or LDA on your own. Instead, you can use [gensim](http://radimrehurek.com/gensim/index.html). An example on how to integrate Pyndri with Gensim for word2vec can be found [here](https://github.com/cvangysel/pyndri/blob/master/examples/word2vec.py). For the remaining latent vector space models, you will need to implement connector classes (such as `IndriSentences`) by yourself.\n",
    "\n",
    "In order to use a latent semantic model for retrieval, you need to:\n",
    "   * build a representation of the query **q**,\n",
    "   * build a representation of the document **d**,\n",
    "   * calculate the similarity between **q** and **d** (e.g., cosine similarity, KL-divergence).\n",
    "     \n",
    "The exact implementation here depends on the latent semantic model you are using. \n",
    "   \n",
    "Each of these LSMs come with various hyperparameters to tune. Make a choice on the parameters, and explicitly mention the reasons that led you to these decisions. You can use the validation set to optimize hyper parameters you see fit; motivate your decisions. In addition, mention clearly how the query/document representations were constructed for each LSM and explain your choices.\n",
    "\n",
    "In this experiment, you will first obtain an initial top-1000 ranking for each query using TF-IDF in **Task 1**, and then re-rank the documents using the LSMs. Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "Perform significance testing **[5 points]** (similar as in Task 1) in the class of semantic matching methods.\n",
    "\n",
    "Perform analysis **[5 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Query-Document parser\n",
    "\n",
    "def query_doc_parser(file_name):\n",
    "    F = open(file_name,\"r\")\n",
    "    query_doc_dictionary={}\n",
    "    for row in F:\n",
    "        if len(row.strip()) == 0:\n",
    "            continue\n",
    "        row=row.split()\n",
    "        _, doc_id = index.document_ids([row[2]])[0]\n",
    "        if row[0] not in query_doc_dictionary.keys():\n",
    "            query_doc_dictionary[row[0]] = [doc_id]\n",
    "        else :\n",
    "            l=query_doc_dictionary[row[0]]\n",
    "            l.append(doc_id)\n",
    "            query_doc_dictionary[row[0]] = l\n",
    "    return query_doc_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import tfidfmodel\n",
    "from gensim.models import lsimodel \n",
    "from gensim.models import ldamodel \n",
    "import pyndri.compat\n",
    "from gensim.similarities import Similarity\n",
    "import os.path\n",
    "\n",
    "class PCorpus(object):\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        dictionary = pyndri.extract_dictionary(index)\n",
    "        docs = pyndri.compat.IndriSentences(index, dictionary)\n",
    "        self.dictionary = corpora.Dictionary(docs)\n",
    "        #TODO\n",
    "        self.dictionary.filter_extremes(no_below=5)\n",
    "    \n",
    "    def save(self, file):\n",
    "        self.dictionary.save(file)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        dictionary = pyndri.extract_dictionary(index)\n",
    "        docs = pyndri.compat.IndriSentences(index, dictionary)\n",
    "        for doc in docs:\n",
    "            yield self.dictionary.doc2bow(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save corpus to file after serialization\n",
    "similarity_index_base = 'simlarity_index'\n",
    "similarity_index_filename = 'similarity_index.index'\n",
    "\n",
    "\n",
    "similarity_index_base_lda = 'simlarity_index_lda'\n",
    "similarity_index_filename_lda = 'similarity_index_lda.index'\n",
    "\n",
    "# TODO: in this special case we know that we have 150 topics\n",
    "corpus_filename = 'corpus.mm'\n",
    "dict_filename = 'corpus.dict'\n",
    "num_topics_LSI = 64\n",
    "num_topics_LDA = 64\n",
    "\n",
    "\n",
    "if not os.path.isfile(corpus_filename):\n",
    "    corpus = PCorpus(index)\n",
    "    corpora.MmCorpus.serialize(corpus_filename, corpus)\n",
    "    corpus.save(dict_filename)\n",
    "# load corpus https://radimrehurek.com/gensim/tut2.html\n",
    "if os.path.isfile(corpus_filename):\n",
    "    dictionary = corpora.Dictionary.load(dict_filename)\n",
    "    corpus = corpora.MmCorpus(corpus_filename)\n",
    "    # initialise lsi model\n",
    "    lsi = lsimodel.LsiModel(corpus,id2word = dictionary, num_topics = num_topics_LSI)\n",
    "    lda = ldamodel.LdaModel(corpus,id2word = dictionary, num_topics = num_topics_LDA)\n",
    "    # transform corpus to LDA space and index it\n",
    "    lsi_corpus = lsi[corpus]\n",
    "    # transform corpus to LSI space and index it\n",
    "    lda_corpus = lda[corpus]\n",
    "\n",
    "    \n",
    "# index corpus for lsi similarity https://radimrehurek.com/gensim/tut3.html\n",
    "if not os.path.isfile(similarity_index_filename):\n",
    "    # transform corpus to LSI space and index it\n",
    "    similarity_index = Similarity(similarity_index_base, lsi_corpus,  num_topics_LSI)\n",
    "    similarity_index.save(similarity_index_filename)\n",
    "else:\n",
    "    similarity_index = Similarity.load(similarity_index_filename)\n",
    "\n",
    "    \n",
    "# index corpus for lda    \n",
    "if not os.path.isfile(similarity_index_filename_lda):\n",
    "    # generated similariy index\n",
    "    lda_similarity_index = Similarity(similarity_index_base_lda, lda_corpus,  num_topics_LDA)\n",
    "    # save simlarity indexed\n",
    "    lda_similarity_index.save(similarity_index_filename_lda)\n",
    "else:\n",
    "    lda_similarity_index = Similarity.load(similarity_index_filename_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking took 48.57645916938782 seconds.\n"
     ]
    }
   ],
   "source": [
    "# parse tf-idf best 1000 docs per query\n",
    "ranked_queries = query_doc_parser(\"tfidf.run\")\n",
    "\n",
    "\n",
    "# iterate through queries\n",
    "scores = collections.defaultdict(list)\n",
    "similarity_index.num_best = None\n",
    "start_time = time.time()\n",
    "for query_id, docs in ranked_queries.items():\n",
    "    # bow for query terms\n",
    "    vec_bow = dictionary.doc2bow((queries[query_id]).lower().split())\n",
    "    # convert the query to LSI space\n",
    "    vec_lsi = lsi[vec_bow] \n",
    "    # get similarity for all documents\n",
    "    sims = similarity_index[vec_lsi]\n",
    "    sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "    # only obtain scores for the docs that were among the 1000 best\n",
    "    for doc_id in docs:\n",
    "        # get document name\n",
    "        doc_name = index.document(doc_id)[0]\n",
    "        scores[int(query_id)].append((sims[doc_id-1][1], doc_name))\n",
    "    \n",
    "lsi_name = 'LSI'\n",
    "# write scores to file\n",
    "with open(lsi_name+'.run', 'w') as f_out:\n",
    "    write_run(\n",
    "        model_name=lsi_name,\n",
    "        data=scores,\n",
    "        out_f=f_out,\n",
    "        max_objects_per_query=1000)\n",
    "print('Ranking took', time.time() - start_time, 'seconds.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'ndcg_cut_10': 0.0431, 'map_cut_1000': 0.0457, 'P_5': 0.0383, 'recall_1000': 0.6491}\n"
     ]
    }
   ],
   "source": [
    "# evalutaion\n",
    "\n",
    "lsi_name = 'LSI'\n",
    "LSI_scores = trec_eval(test_data, lsi_name+'.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(LSI_scores))))\n",
    "LSI_scores = restruct(LSI_scores,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking took 44.39399003982544 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iterate through queries\n",
    "scores = collections.defaultdict(list)\n",
    "lda_similarity_index.num_best = None\n",
    "start_time = time.time()\n",
    "for query_id, docs in ranked_queries.items():\n",
    "    # bow for query terms\n",
    "    vec_bow = dictionary.doc2bow((queries[query_id]).lower().split())\n",
    "    # convert the query to LSI space\n",
    "    vec_lda = lda[vec_bow] \n",
    "    # get similarity for all documents\n",
    "    sims = lda_similarity_index[vec_lsi]\n",
    "    sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "    # only obtain scores for the docs that were among the 1000 best\n",
    "    for doc_id in docs:\n",
    "        # get document name\n",
    "        doc_name = index.document(doc_id)[0]\n",
    "        scores[int(query_id)].append((sims[doc_id-1][1], doc_name))\n",
    "    \n",
    "lda_name = 'LDA'\n",
    "# write scores to file\n",
    "with open(lda_name+'.run', 'w') as f_out:\n",
    "    write_run(\n",
    "        model_name=lda_name,\n",
    "        data=scores,\n",
    "        out_f=f_out,\n",
    "        max_objects_per_query=1000)\n",
    "print('Ranking took', time.time() - start_time, 'seconds.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'ndcg_cut_10': 0.0442, 'map_cut_1000': 0.0457, 'P_5': 0.04, 'recall_1000': 0.6491}\n"
     ]
    }
   ],
   "source": [
    "# evalutaion\n",
    "LDA_scores = trec_eval(test_data, lda_name+'.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(LDA_scores))))\n",
    "LDA_scores = restruct(LDA_scores,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare LSI with LDA\n",
      "H0 accepted for ndcg_cut_10\n",
      "H0 accepted for map_cut_1000\n",
      "H0 accepted for P_5\n",
      "H0 accepted for recall_1000\n"
     ]
    }
   ],
   "source": [
    "print('Compare LSI with LDA')\n",
    "compute_ttest(LSI_scores, LDA_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Word embeddings for ranking [20 points] (open-ended) ###\n",
    "\n",
    "First create word embeddings on the corpus we provided using [word2vec](http://arxiv.org/abs/1411.2738) -- [gensim implementation](https://radimrehurek.com/gensim/models/word2vec.html). You should extract the indexed documents using pyndri and provide them to gensim for training a model (see example [here](https://github.com/nickvosk/pyndri/blob/master/examples/word2vec.py)).\n",
    "   \n",
    "This is an open-ended task. It is left up you to decide how you will combine word embeddings to derive query and document representations. Note that since we provide the implementation for training word2vec, you will be graded based on your creativity on combining word embeddings for building query and document representations.\n",
    "\n",
    "Note: If you want to experiment with pre-trained word embeddings on a different corpus, you can use the word embeddings we provide alongside the assignment (./data/reduced_vectors_google.txt.tar.gz). These are the [google word2vec word embeddings](https://code.google.com/archive/p/word2vec/), reduced to only the words that appear in the document collection we use in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyndri.compat\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "word2vec_filename = 'word2vec_model'\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "dictionary = pyndri.extract_dictionary(index)\n",
    "sentences = pyndri.compat.IndriSentences(index, dictionary)\n",
    "\n",
    "if not os.path.isfile(word2vec_filename):\n",
    "    #initialize model use cbow\n",
    "    model = Word2Vec(sentences, size=32, window=5, min_count=5, workers=cores, sg=0)\n",
    "    model.wv.save_word2vec_format(word2vec_filename, binary=True)\n",
    "    \n",
    "else:\n",
    "    # load model \n",
    "    word2vec_model = KeyedVectors.load_word2vec_format(word2vec_filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7283260822296143),\n",
       " ('officiate', 0.68340665102005),\n",
       " ('elizabeth', 0.6806406378746033),\n",
       " ('kings', 0.6773276925086975),\n",
       " ('sanger', 0.6747434139251709),\n",
       " ('dovydenas', 0.6722996830940247),\n",
       " ('prayerbook', 0.660342812538147),\n",
       " ('beatrice', 0.6596303582191467),\n",
       " ('matilda', 0.6566049456596375),\n",
       " ('burger', 0.6554551124572754)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Average vec:\n",
    "- transform query and document into higher dimensional space\n",
    "- average vector for query and document\n",
    "- calculate cosine similarity between the two vectors\n",
    "\n",
    "#### Assumption: if query term is not in corpus vocabulary discard it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "\n",
    "# Transform each query and each unique document in a representation.\n",
    "from scipy import spatial\n",
    "\n",
    "def average_vec(vecs):\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "# frequencies of a word in the whole collection\n",
    "id2freq = index.get_term_frequencies()\n",
    "\n",
    "# parse tf-idf best 1000 docs per query\n",
    "ranked_queries = query_doc_parser(\"tfidf.run\")    \n",
    "# iterate through queries    \n",
    "scores = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking took 204.66667890548706 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "AV_name = 'AV'\n",
    "if not os.path.exists(AV_name + '.run'):\n",
    "    for query_id, docs in ranked_queries.items():\n",
    "        query_terms = []\n",
    "        for term_id in tokenized_queries[query_id]:\n",
    "            query_token = id2token[term_id] \n",
    "            if query_token in word2vec_model.wv.vocab:\n",
    "                query_terms.append( query_token ) \n",
    "        vec_query = average_vec([word2vec_model.wv[word] for word in query_terms])\n",
    "        for doc_id in docs:\n",
    "            document = index.document(doc_id)\n",
    "            terms_doc = [id2token[word_id] for word_id in document[1] if word_id > 0 and id2freq[word_id] > 5 ]\n",
    "            vec_doc = average_vec([word2vec_model.wv[word] for word in terms_doc])\n",
    "            # computes dist, therefor 1 - dist is similarity  \n",
    "            score = 1 - spatial.distance.cosine(vec_query, vec_doc)\n",
    "            scores[int(query_id)].append((score, document[0]))\n",
    "\n",
    "    # write scores to file\n",
    "    with open(AV_name+'.run', 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=AV_name,\n",
    "            data=scores,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "    print('Ranking took', time.time() - start_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'ndcg_cut_10': 0.2823, 'map_cut_1000': 0.1361, 'P_5': 0.2883, 'recall_1000': 0.6491}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evalutaion\n",
    "AV_scores = restruct(trec_eval(test_data, AV_name+'.run'))\n",
    "print('Scores:', dict(zip(measure_names, AV_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Centroid vec:\n",
    "- transform query and document into higher dimensional space\n",
    "- average vector for query and document\n",
    "- calculate cosine similarity between the two vectors\n",
    "\n",
    "Note: right now we are discarding words with count in all documents < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centroid_similarity(query, docs, k):\n",
    "    \"\"\"\n",
    "    takes query and docs as embedding vectors\n",
    "    - clusters docuemnt embeddings into k cluster\n",
    "    - calculates the similarity between the average embedding of query (can consist of multiple words)\n",
    "    and the most important (cointains biggest number of datapoints) centroid\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(docs)\n",
    "    most_common_centroid = collections.Counter(kmeans.labels_).most_common(1)[0][0]\n",
    "    center = np.array(kmeans.cluster_centers_[most_common_centroid])\n",
    "    # computes dist, therefor 1 - dist is similarity \n",
    "    return 1 - spatial.distance.cosine(average_vec(query), center)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5ae5d081bdb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mterms_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid2token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword_id\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mid2freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mvec_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms_doc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentroid_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvec_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# write scores to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-5ae5d081bdb7>\u001b[0m in \u001b[0;36mcentroid_similarity\u001b[0;34m(query, docs, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mimportant\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcointains\u001b[0m \u001b[0mbiggest\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdatapoints\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mcentroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmost_common_centroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmost_common_centroid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml1labs/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml1labs/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml1labs/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialization complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     centers, labels, n_iter = k_means_elkan(X, n_clusters, centers, tol=tol,\n\u001b[0;32m--> 400\u001b[0;31m                                             max_iter=max_iter, verbose=verbose)\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0minertia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/cluster/_k_means_elkan.pyx\u001b[0m in \u001b[0;36msklearn.cluster._k_means_elkan.k_means_elkan\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml1labs/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# Pairwise distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m def euclidean_distances(X, Y=None, Y_norm_squared=None, squared=False,\n\u001b[0m\u001b[1;32m    164\u001b[0m                         X_norm_squared=None):\n\u001b[1;32m    165\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# iterate through queries    \n",
    "\n",
    "ks = [3,7]\n",
    "\n",
    "for k in ks:\n",
    "    start_time = time.time()\n",
    "    CV_name = 'CV_' + str(k)\n",
    "    if not os.path.exists(CV_name + '.run'):\n",
    "        scores = collections.defaultdict(list)\n",
    "        for query_id, docs in ranked_queries.items():\n",
    "            query_terms = []\n",
    "            for term_id in tokenized_queries[query_id]:\n",
    "                query_token = id2token[term_id] \n",
    "                if query_token in word2vec_model.wv.vocab:\n",
    "                    query_terms.append( query_token ) \n",
    "            vec_query = [word2vec_model.wv[word] for word in query_terms]\n",
    "            for doc_id in docs:\n",
    "                document = index.document(doc_id)\n",
    "                terms_doc = [id2token[word_id] for word_id in document[1] if word_id > 0 and id2freq[word_id] > 5 ]\n",
    "                vec_doc = [word2vec_model.wv[word] for word in terms_doc]\n",
    "                score = centroid_similarity(vec_query,vec_doc, k )\n",
    "                scores[int(query_id)].append((score, document[0]))\n",
    "        # write scores to file\n",
    "        with open(CV_name+'.run', 'w') as f_out:\n",
    "            write_run(\n",
    "                model_name=CV_name,\n",
    "                data=scores,\n",
    "                out_f=f_out,\n",
    "                max_objects_per_query=1000)\n",
    "        print('Ranking took', time.time() - start_time, 'seconds.')\n",
    "CV_name = 'CV_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_3.run\n",
      "Scores: {'ndcg_cut_10': 0.152, 'map_cut_1000': 0.0797, 'P_5': 0.1517, 'recall_1000': 0.6491}\n",
      "Scores: {'ndcg_cut_10': 0.1512, 'map_cut_1000': 0.072, 'P_5': 0.1617, 'recall_1000': 0.6491}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZZ/X/l760HH2wscQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a34f6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CV_name = 'CV_'\n",
    "# evalutaion\n",
    "CV_scores_3 = restruct(trec_eval(test_data, CV_name+'3.run'))\n",
    "print(CV_name+'3.run')\n",
    "print('Scores:', dict(zip(measure_names, CV_scores_3)))\n",
    "\n",
    "CV_scores_7 = restruct(trec_eval(test_data, CV_name+'7.run'))\n",
    "print('Scores:', dict(zip(measure_names, CV_scores_7)))\n",
    "\n",
    "# print ndcg_cut_10 for k (number of clusters) 1,3,7 \n",
    "# TODO: maybe use another measure ??\n",
    "CV_scores = [AV_scores[0], CV_scores_3[0],CV_scores_7[0]]\n",
    "plot_validation(CV_scores, [1,3,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Learning to rank (LTR) [15 points] (open-ended) ###\n",
    "\n",
    "In this task you will get an introduction into learning to rank for information retrieval.\n",
    "\n",
    "You can explore different ways for devising features for the model. Obviously, you can use the retrieval methods you implemented in Task 1, Task 2 and Task 3 as features. Think about other features you can use (e.g. query/document length). Creativity on devising new features and providing motivation for them will be taken into account when grading.\n",
    "\n",
    "For every query, first create a document candidate set using the top-1000 documents using TF-IDF, and subsequently compute features given a query and a document. Note that the feature values of different retrieval methods are likely to be distributed differently.\n",
    "\n",
    "You are adviced to start some pointwise learning to rank algorithm e.g. logistic regression, implemented in [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "Train your LTR model using 10-fold cross validation on the test set. More advanced learning to rank algorithms will be appreciated when grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ground_truth_parser(file_name):\n",
    "    \"\"\"\n",
    "    parse ground truth and build dict\n",
    "    \n",
    "    query_id -> (document, score)\n",
    "    \n",
    "    where score is 1: relevant, 0: not relevant\n",
    "    \n",
    "    \"\"\"\n",
    "    F = open(file_name,\"r\")\n",
    "    result= collections.defaultdict(list)\n",
    "    last_query_id = None\n",
    "    document_dict = collections.defaultdict(list)\n",
    "    for row in F: \n",
    "        if len(row.strip()) == 0:\n",
    "            continue\n",
    "        row=row.split()\n",
    "        doc_id = row[2]\n",
    "        query_id = row[0]\n",
    "        if query_id != last_query_id and not None:\n",
    "            result[last_query_id] = document_dict\n",
    "            document_dict = collections.defaultdict(list)\n",
    "        try:\n",
    "            doc_index = index.document_ids([doc_id])[0][1]\n",
    "            document_dict[doc_index] = int(row[3])       \n",
    "            last_query_id = row[0]\n",
    "        except:\n",
    "            print('document key error',row)\n",
    "            None\n",
    "    result[last_query_id] = document_dict\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "def query_expansion(query_tokens):\n",
    "    text = []\n",
    "    for query_token in query_tokens:\n",
    "        text.append(query_token)\n",
    "        if query_token in word2vec_model.wv.vocab:\n",
    "            for extracted_word in word2vec_model.wv.most_similar(query_token.lower()):\n",
    "                text.append(extracted_word[0])\n",
    "    return ' '.join(text)\n",
    "\n",
    "def doc_sent(doc_id):\n",
    "    text= ' '.join([id2token[word_id] for word_id in index.document(doc_id)[1] if word_id > 0])\n",
    "    blob = TextBlob(text)\n",
    "    polarity=0\n",
    "    \n",
    "    for sentence in blob.sentences:\n",
    "        polarity+=sentence.sentiment.polarity\n",
    "    \n",
    "    return polarity\n",
    "\n",
    "def query_sent(q_id):\n",
    "    text=query_expansion(queries[q_id].split())\n",
    "    blob = TextBlob(text)\n",
    "    polarity=0\n",
    "    \n",
    "    for sentence in blob.sentences:\n",
    "        polarity+=sentence.sentiment.polarity\n",
    "    \n",
    "    return polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11738672726 -0.404663081566\n"
     ]
    }
   ],
   "source": [
    "def mean_cosine_similarity(query_id,document_id):\n",
    "    query_terms=[]\n",
    "    for term_id in tokenized_queries[query_id]:\n",
    "        query_token = id2token[term_id] \n",
    "        if query_token in word2vec_model.wv.vocab:\n",
    "            query_terms.append( query_token )\n",
    "        \n",
    "    vec_query = average_vec([word2vec_model.wv[word] for word in query_terms])\n",
    "    document = index.document(document_id)\n",
    "    terms_doc = [id2token[word_id] for word_id in document[1] if word_id > 0 and id2freq[word_id] > 5 ]\n",
    "    vec_doc = average_vec([word2vec_model.wv[word] for word in terms_doc])\n",
    "    return 1 - spatial.distance.cosine(vec_query, vec_doc)\n",
    "\n",
    "def centroid_cosine_similarity(query_id,document_id):\n",
    "    query_terms=[]\n",
    "    for term_id in tokenized_queries[query_id]:\n",
    "        query_token = id2token[term_id] \n",
    "        if query_token in word2vec_model.wv.vocab:\n",
    "            query_terms.append( query_token )\n",
    "        \n",
    "    vec_query = [word2vec_model.wv[word] for word in query_terms]\n",
    "    document = index.document(document_id)\n",
    "    terms_doc = [id2token[word_id] for word_id in document[1] if word_id > 0 and id2freq[word_id] > 5 ]\n",
    "    vec_doc = [word2vec_model.wv[word] for word in terms_doc]\n",
    "    return centroid_similarity(vec_query,vec_doc, 8 )\n",
    "\n",
    "print(mean_cosine_similarity(\"51\",1),centroid_cosine_similarity('51',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_methods(query_id, int_document_id):\n",
    "    #TODO add more features\n",
    "    scores = []\n",
    "    scores.append(tfidf(int_document_id, query_id, positional_inverted_index, None ))\n",
    "    scores.append(BM25(int_document_id, query_id, positional_inverted_index , None ))\n",
    "    scores.append(JM(int_document_id, query_id, positional_inverted_index , 0.1))\n",
    "    scores.append(ADS(int_document_id, query_id, positional_inverted_index , 0.5))\n",
    "    scores.append(DP(int_document_id, query_id, positional_inverted_index , 500))\n",
    "    scores.append(mean_cosine_similarity(query_id,int_document_id)) # distance between the mean average vector of document and a query\n",
    "    try:\n",
    "        scores.append(centroid_cosine_similarity(query_id,int_document_id)) # distance between document's most important cluster and query \n",
    "    except:\n",
    "        print(\"err\",query_id, int_document_id)\n",
    "        scores.append(0)\n",
    "    scores.append((document_lengths[int_document_id]/len(tokenized_queries[query_id]))) # document length compared with query length \n",
    "    scores.append((unique_terms_per_document[int_document_id]/len(tokenized_queries[query_id]))) # unique word in document lengh compared with query length \n",
    "    scores.append(query_sent(query_id)) # sentiment polarity of query\n",
    "    scores.append(doc_sent(int_document_id)) # sentiment polarity of document\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(ranked_queries):\n",
    "    result = collections.defaultdict(list)\n",
    "    for query_id, docs in ranked_queries.items():\n",
    "        if query_id==None:\n",
    "            continue\n",
    "        dict_document = collections.defaultdict(list)\n",
    "        for document_id in docs:\n",
    "            dict_document[document_id] = run_methods(query_id,document_id)\n",
    "        result[str(query_id)] = dict_document\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.document_ids(['AP901121-0246'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document key error ['149', '0', 'AP900109-0232', '0']\n",
      "document key error ['149', '0', 'AP900214-0247', '0']\n",
      "document key error ['149', '0', 'AP900215-0091', '0']\n",
      "document key error ['149', '0', 'AP900327-0168', '1']\n",
      "document key error ['149', '0', 'AP900427-0031', '1']\n",
      "document key error ['149', '0', 'AP900429-0093', '0']\n",
      "document key error ['149', '0', 'AP900607-0165', '0']\n",
      "document key error ['149', '0', 'AP900904-0175', '0']\n",
      "document key error ['149', '0', 'AP900913-0007', '0']\n",
      "document key error ['149', '0', 'AP901121-0246', '0']\n",
      "err 184 91412\n",
      "err 152 30952\n",
      "err 178 114626\n",
      "err 166 105987\n",
      "err 166 154627\n",
      "err 166 86167\n",
      "err 166 119294\n",
      "err 166 119297\n",
      "err 166 153612\n",
      "err 166 86651\n",
      "err 166 21521\n",
      "err 166 42823\n",
      "err 166 43880\n",
      "err 166 18746\n",
      "err 166 48982\n",
      "err 166 15120\n",
      "err 96 105987\n",
      "err 96 153612\n",
      "err 190 91412\n",
      "err 121 114626\n"
     ]
    }
   ],
   "source": [
    "# parse ground truth\n",
    "ground_truth = ground_truth_parser('ap_88_89/qrel_test')\n",
    "# obtain features from different ranking methods / other measures\n",
    "features = get_features(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([None, '68', '61', '101', '142', '176', '82', '106', '163', '199', '137', '153', '184', '146', '91', '186', '200', '149', '198', '131', '72', '171', '152', '183', '161', '81', '187', '97', '122', '169', '197', '66', '105', '80', '65', '177', '88', '160', '115', '83', '52', '70', '79', '141', '117', '124', '84', '178', '136', '172', '185', '134', '145', '76', '140', '166', '98', '128', '130', '85', '75', '60', '147', '107', '108', '133', '100', '139', '162', '189', '102', '118', '55', '51', '63', '96', '119', '129', '188', '125', '157', '164', '56', '174', '148', '154', '59', '138', '58', '194', '112', '126', '190', '99', '116', '121', '71', '54', '175', '168', '191', '110', '87', '64', '159', '193', '77', '62', '132', '179', '127', '67', '104', '156', '73', '195', '150', '196', '181', '109', '113'])\n"
     ]
    }
   ],
   "source": [
    "print( ground_truth.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption:  For document-query pairs that do not exist in qrel file we assume that are irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill Features and targets into arrays\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for query_id, docs in ground_truth.items():\n",
    "    if query_id == None:\n",
    "        continue\n",
    "    for document_id in docs:\n",
    "        # if document is in ifidf best 1000 ranking but not in ground truth discard it\n",
    "        if ground_truth[query_id][document_id] is 0 or ground_truth[query_id][document_id] is 1:\n",
    "            f=features[query_id][document_id]\n",
    "            if len(f)!=0:\n",
    "                Y.append(ground_truth[query_id][document_id])\n",
    "                X.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.4304953907708207, 3.5668920914354878, -50.420599981381606, -52.401726197291168, -51.367375317784365, 0.66059132898400807, 0.35150075197527086, 84.8, 59.2, 0.0, 0.01460243188184365], [14.289658802709233, 10.697715809333133, -46.30306008784202, -45.621086066260801, -45.54019136686469, 0.54234856299120193, 0.23295337392849391, 73.0, 49.0, 0.0, 0.13042790542790542], [24.872923763034379, 18.466353983270206, -42.309803027948874, -38.417563062998653, -39.71555876632172, 0.56879801719497736, 0.26572379905156107, 68.0, 43.8, 0.0, 0.08925603965926546], [0, 0, -51.321445523171938, -55.863941838323854, -52.998804204610082, -0.24026368322765301, -0.11080168910413302, 55.4, 40.2, 0.0, -0.030681818181818185], [0, 0, -51.321445523171938, -56.958565452705216, -52.638648563565674, 0.49550472507257215, 0.20755213767135872, 44.6, 26.0, 0.0, -0.004347826086956516], [14.065985852389934, 10.864748151824807, -45.698353726026994, -44.171414928295206, -44.309647124469052, 0.60735742178293084, 0.2392435477238819, 50.4, 34.2, 0.0, 0.03316336441336441], [0, 0, -51.321445523171938, -56.662980219035845, -53.298519384445257, 0.57794198041370382, 0.10732594963818853, 65.0, 40.2, 0.0, 0.011320260427403287], [2.5876601505165584, 2.2360738861730236, -50.862800832311827, -53.483025232509888, -51.925613906573474, 0.28246935980795684, 0.36692717942812525, 71.0, 47.2, 0.0, -0.06963636363636364], [19.306866919758686, 15.990278116775837, -42.895890968798184, -38.805180262397265, -40.31358753507967, 0.49225055250781613, 0.085232895998004432, 64.8, 45.2, 0.0, 0.0008207070707070737], [14.708847845444389, 14.750984449579382, -44.491109750106922, -39.759777765524234, -42.261974141876578, 0.34609008803036367, -0.017098510463581462, 37.4, 29.0, 0.0, -0.009499999999999991], [12.395478006526304, 11.172536726701342, -46.288374633400736, -45.146932810952912, -45.328102049038094, 0.43085707600411149, 0.076445901819081064, 42.2, 30.0, 0.0, 0.07414772727272728], [15.238313246780566, 10.92481177131665, -46.481495218363897, -45.40113352358901, -45.315637890697055, 0.43343193526334445, 0.27109013726638698, 71.4, 46.2, 0.0, 0.015261363636363634], [5.4304953907708207, 3.9812827512716411, -50.159010967541164, -51.724049806593499, -50.533088662302504, 0.38310379499929481, -0.039902006432502857, 56.4, 42.2, 0.0, 0.09493145743145742], [8.4894585933788118, 7.2464049634437062, -48.910591593693852, -48.119457751719345, -48.113943670052919, 0.44418042745232222, 0.43162658471100634, 54.2, 37.6, 0.0, 0.06736507936507936], [6.1749188256723109, 4.0021398112745619, -50.194338618706077, -52.253930260896595, -50.946616095277349, 0.46270948782174881, 0.29250616442119504, 79.2, 52.6, 0.0, 0.1255969836614998], [20.679244530746324, 12.684449009801124, -45.724349793206329, -44.781788600898928, -44.70683582555403, 0.42463759576993465, 0.13490165199598159, 102.4, 63.6, 0.0, -0.003844766344766335], [16.08328814028711, 13.168620540882397, -45.394360232915147, -43.661880378262225, -44.239102321761884, 0.44905217645014683, 0.28566021844958067, 49.8, 40.0, 0.0, -0.06491228070175441], [5.4304953907708207, 4.5809449904079882, -49.516449072951609, -50.99829797635855, -49.388515423271841, 0.37825101702203534, 0.15541067771436945, 24.4, 17.8, 0.0, 0.10004329004329003], [6.0733573838252735, 6.6393552885326077, -49.103678637564549, -48.175437728985735, -48.309021767729938, 0.48972435795337343, 0.13368846188969685, 40.6, 28.8, 0.0, 0.11944444444444448], [7.2241247283486958, 4.5328954348419481, -49.812639571567239, -51.803120135276792, -50.310603737105254, 0.43433634483460248, -0.036000938075061439, 70.4, 46.0, 0.0, 0.04466942148760333], [0, 0, -51.321445523171938, -55.326344949987742, -51.910360701453861, 0.43693512502850862, -0.040682521169354002, 25.0, 20.2, 0.0, -0.0033333333333333214], [0, 0, -51.321445523171938, -55.438990515287884, -52.477004127988877, 0.36599813312534535, 0.18753512506770864, 40.0, 31.6, 0.0, -0.010714285714285714], [0, 0, -51.321445523171938, -55.57220017001999, -52.801928378435932, 0.2628052357906081, 0.17304485273954773, 49.4, 38.0, 0.0, -0.05765432098765432], [0, 0, -51.321445523171938, -55.917164527454744, -53.892146146841036, 0.28427738716816453, 0.1090561329509131, 85.8, 61.6, 0.0, -0.011590909090909084], [5.4304953907708207, 3.3301201533385392, -50.537750940651136, -52.711007269904748, -51.866504050399271, 0.41248296500129178, -0.0029526579227949767, 104.2, 70.8, 0.0, 0.08475490196078435], [4.3812894880944349, 3.3536678617628333, -50.47804362714173, -52.243497715408225, -51.086471834668558, 0.30645287555748635, 0.11451976181204016, 62.4, 46.4, 0.0, 0.025188620902906626], [17.319475689159798, 10.403715590095933, -47.386457853939888, -46.506187566109588, -46.243719974013644, 0.58400700670955474, 0.4759958685350919, 81.6, 49.2, 0.0, 0.07132896015549076], [23.278994584587018, 15.175952074065609, -44.320641956985611, -40.029040565971307, -41.175336619708602, 0.54192339319950522, 0.50614107799307972, 82.0, 49.6, 0.0, -0.04608015873015873], [2.5876601505165584, 3.0015540037008814, -50.526101162984162, -52.604310689729772, -50.706495123814733, 0.31388519467002696, 0.27866078629680413, 34.0, 23.6, 0.0, -0.06666666666666667], [7.968548163250186, 4.2408080349599713, -50.104175751308148, -52.363513644042172, -51.725278760451104, 0.26945597715047243, 0.35454058187312798, 139.0, 87.0, 0.0, 0.02739769345238096], [17.876917477864986, 13.398001436033089, -45.199468437357346, -43.665498512333478, -43.898768606953986, 0.54026641789617758, 0.21744067638229125, 58.8, 42.0, 0.0, 0.009595959595959607], [8.3803153718814105, 10.98050560836935, -45.924996432685674, -44.320879539496431, -45.23533794612247, 0.56326894301744956, 0.00051865618113788869, 21.6, 16.4, 0.0, 0.07550505050505052], [13.016779949713548, 9.2626938420531602, -46.796666098963129, -45.599311467255347, -45.520612830386035, 0.58308983786175528, 0.40789674899718897, 77.2, 49.4, 0.0, -0.035995085995086], [2.5876601505165584, 2.6061118679392203, -50.722729760481222, -53.31843926056446, -51.283788181638883, 0.50792907469416693, 0.45028700882621586, 50.4, 32.2, 0.0, -0.03720238095238093], [5.7926552213648517, 5.4899619076883557, -47.963185549280468, -49.87944713294749, -48.102449266012073, 0.44316409920038313, 0.031668700931896554, 58.2, 36.8, 0.0, -0.005555555555555554], [10.397086146541099, 12.645065229770228, -44.736193709921075, -42.961021926897715, -43.677979769048065, 0.51424640075867167, 0.20983837301890207, 29.0, 21.6, 0.0, -0.013351158645276282], [8.3803153718814105, 8.5222262489130465, -47.190945900306815, -46.052035329897848, -46.258091537310435, 0.47558065803322902, -0.02347946267360923, 49.2, 36.0, 0.0, 0.05], [15.187695885501391, 13.759694811988126, -44.722121285497089, -43.362642794339152, -43.473532618890601, 0.56344263696569985, 0.1900089481446523, 42.2, 28.0, 0.0, -0.012134986225895312], [8.5459678388307143, 5.0740605951399456, -49.137091251688062, -51.030679329933271, -49.258886360510246, 0.65038877423115227, 0.34278148984528145, 52.4, 34.0, 0.0, 0.09823529411764707], [8.792598193048935, 5.0736969134529017, -49.163737945678626, -51.224126447156593, -49.390500374146562, 0.6313773561717988, 0.38245431962572374, 59.4, 37.0, 0.0, 0.0022807017543859695], [12.341884304003203, 11.728028369251117, -45.49973898715217, -44.288473330836631, -44.284030413554959, 0.36828035172920492, 0.2256192215784808, 41.6, 26.6, 0.0, -0.0008928571428571414], [7.8669867214031504, 6.8724940162820136, -49.116905775764486, -48.161797904476074, -48.215416027413838, 0.43267377488865133, 0.14747362599012204, 55.0, 38.2, 0.0, 0.14050116550116548], [9.4990490637489415, 8.9890885646102348, -46.680363033001093, -45.640607035261759, -45.790908506472221, 0.57155662360874326, 0.21857003675389952, 58.4, 42.4, 0.0, 0.014943792766373405], [0, 0, -51.321445523171938, -57.372269396041219, -53.14466109111148, 0.5282085962541142, 0.25820369845878965, 60.0, 32.2, 0.0, -0.018777056277056274], [8.4894585933788118, 7.7397087872528463, -48.636753473392943, -47.685511747676443, -47.771757862286776, 0.43955260507303406, 0.40709469896659223, 44.0, 30.8, 0.0, 0.028787878787878796], [22.884641076955422, 17.401084742515554, -42.650006969410271, -38.812097802430884, -40.050369261165415, 0.6842362215361586, 0.53807504273855933, 69.6, 44.0, 0.0, 0.01685992578849722], [0, 0, -51.321445523171938, -55.84658322114916, -51.731188436407777, 0.027067277864122774, 0.016385411113764237, 20.6, 15.0, 0.0, -0.06818181818181818], [7.8669867214031504, 7.4492246238209496, -48.784600003899463, -47.607971687563278, -47.819501715450329, 0.38487209469024419, 0.29696077052033232, 43.2, 30.8, 0.0, 0.10301136363636362], [4.3812894880944349, 3.8195965213119862, -50.180496090228935, -52.655602594039209, -50.301329936394197, 0.23393291636277413, 0.085937347896374194, 38.8, 23.2, 0.0, 0.057670454545454525], [0, 0, -51.321445523171938, -56.586066045655343, -52.213013200154023, 0.21896764105696209, 0.48751740610809113, 32.8, 20.6, 0.0, 0.016883116883116882], [2.5876601505165584, 2.3392657770465379, -50.827004868091876, -53.258862125090126, -51.734887565275024, 0.50067939140794093, 0.18164143554212653, 64.6, 44.4, 0.0, -0.04028787878787878], [6.7523385012528383, 4.5662943095667758, -49.735650986071377, -51.083657518178057, -49.952360514906871, 0.56593209906660491, 0.39488137746669716, 53.2, 40.6, 0.0, -0.125326420890937], [5.4304953907708207, 4.2085340775031561, -49.968389758660379, -52.55737372900554, -50.092215794379172, 0.49882759975241808, 0.31153058421723379, 43.2, 24.6, 0.0, 0.0830357142857143], [9.4990490637489415, 6.7099354518813143, -47.437884036136971, -47.263408183955043, -47.041163527642901, 0.34198069878078208, 0.61469395434710483, 103.4, 63.4, 0.0, 0.033852353320438434], [4.3812894880944349, 4.0433427828732285, -49.983639129444725, -51.338306532339473, -49.950701606364674, 0.54227602675047082, 0.24906952893943191, 29.4, 22.8, 0.0, 0.09], [11.701998652192675, 9.6668379584927653, -46.34000039927728, -48.567844779777381, -46.318042849567902, 0.67216160173789019, 0.19574216020428103, 48.2, 28.0, 0.0, 0.03209366391184573], [5.4304953907708207, 3.6199600479300251, -50.391628972417983, -52.039538412032066, -51.257961761536826, 0.52728118618371034, 0.058070241770079911, 80.8, 61.0, 0.0, 0.08658633033633033], [15.161723648722459, 10.768936727592054, -46.874335565099628, -45.488925268567641, -45.681955275913772, 0.49757314843047273, 0.4072351112593513, 42.0, 28.8, 0.0, 0.13729296066252586], [16.955352986300333, 10.066896003612609, -47.72081777566482, -46.592246931683633, -46.611543087332372, 0.52438632705253174, 0.42184018954771019, 94.8, 61.4, 0.0, 0.008900226757369619], [13.748395043186612, 9.5920141018069405, -47.885193968673114, -46.729151545944461, -46.733772999554844, 0.47772326566154111, 0.10025111835009282, 61.8, 41.4, 0.0, 0.03233736983736985], [16.483566759204479, 10.101175082914391, -47.670553235800348, -46.6021984089329, -46.521825490573349, 0.56748209376508696, 0.32435067110245097, 84.8, 54.0, 0.0, 0.026673101673101676], [5.9017984428622539, 4.9248326416973667, -49.344854823935016, -50.85110745662719, -49.405900262925002, 0.62016080199779711, 0.28531105744773244, 46.4, 33.4, 0.0, 0.20489332096474952], [11.696416536492539, 9.0904872890593662, -48.078339739120104, -46.381946035129857, -47.001704229689004, 0.14415869318756935, 0.019208102965584395, 50.0, 41.0, 0.0, 0.12144660894660889], [4.3812894880944349, 3.1982741384216271, -50.555564142442968, -52.808444901368993, -51.367814743781445, 0.39428516147905435, 0.35241227492453131, 71.8, 48.0, 0.0, 0.07362068965517242], [2.5876601505165584, 2.7995201093861302, -50.634093504362866, -52.642044159610663, -50.989384194550318, 0.44534419973818529, 0.30704597602092099, 41.8, 30.2, 0.0, -0.10444444444444445], [4.3812894880944349, 2.980812832035816, -50.651463845659137, -53.629612552265726, -51.780996138096889, 0.47831314347922804, 0.30121936979425712, 86.6, 49.4, 0.0, -0.0015226070226070224], [4.3812894880944349, 3.810623402987158, -50.187464029220969, -52.038545678947585, -50.315718435532268, 0.3684322474257038, 0.24885382273603684, 39.2, 27.4, 0.0, 0.07256944444444445], [16.075743152321539, 10.954516321797591, -46.441628161901342, -42.522034910210841, -43.756678890381046, 0.47962277275542986, 0.13458229020862333, 96.4, 66.2, 0.0, 0.05552910052910052], [14.135513641581078, 9.8217740413447796, -46.222091270141128, -44.881531762210386, -44.975037261699995, 0.35860953290029762, -0.066293661200389264, 85.2, 57.2, 0.0, -0.01283549783549784], [4.3812894880944349, 3.3957931025645078, -50.455509220216477, -51.995610473308261, -51.012028772199805, 0.086236943844717362, 0.17682275361611199, 60.0, 47.0, 0.0, 0.1364853896103896], [4.3812894880944349, 3.6152813096223722, -50.325489641321766, -52.320812010167714, -50.635716349697077, 0.39671231757508596, 0.28586214284789702, 48.4, 33.2, 0.0, 0.08], [2.5876601505165584, 2.4303954330286217, -50.793425884726275, -53.323520361373831, -51.574379955840755, 0.42702094421629488, 0.19532974638234846, 59.4, 39.4, 0.0, 0.08064785788923719], [4.3812894880944349, 3.5754365645420143, -50.350833082460383, -52.219968366224641, -50.702651753609373, 0.44666615148996325, 0.13642459664731277, 50.4, 35.8, 0.0, 0.04699074074074075], [0, 0, -51.321445523171938, -56.664016810726096, -54.736929746704163, 0.21403910985267649, 0.11193053525269481, 120.0, 74.2, 0.0, 0.01848620129870129], [12.654136944115091, 9.232894662896328, -47.936023422030445, -46.672959308681342, -46.722607507466606, 0.61907066579833014, 0.48250396627750103, 55.2, 37.2, 0.0, 0.04305555555555556], [16.698215024297202, 13.643900669246975, -45.067840084433946, -40.975283012091168, -42.607137564249733, 0.55944745301569176, 0.53291488955784894, 59.0, 42.0, 0.0, -0.0015999999999999882], [2.5876601505165584, 2.7197230174098279, -50.67220254380539, -53.169033740946659, -51.107856636013658, 0.25880776973279818, -0.0011415886559504873, 45.2, 29.2, 0.0, -0.14452690166975882], [2.5876601505165584, 1.8319994721682116, -50.984162758135703, -54.207549101661549, -52.783326019269126, 0.27365044877943989, 0.32530120593635403, 103.0, 62.4, 0.0, 0.018471407624633434], [11.6880184369384, 11.530528957533285, -44.289863671099191, -42.909635277010935, -42.812364236850335, 0.53562682929426442, 0.32013453937230274, 53.0, 33.2, 0.0, -0.04120670995670995], [14.065985852389934, 11.728366583426112, -45.089671445377626, -43.73654843297156, -43.821113793937158, 0.61328177054848032, 0.25475245154128279, 36.4, 23.0, 0.0, 0.010754870129870128], [0, 0, -51.321445523171938, -55.804800248194454, -52.052326073959946, 0.3501226478975128, 0.57844155743880388, 28.6, 21.0, 0.0, 0.12625000000000003], [11.223150612135672, 11.353935295057298, -45.740562715055681, -44.051723899629302, -44.661348112154151, 0.43794437152466825, 0.78530580488880353, 31.0, 22.8, 0.0, -0.011607142857142858], [14.18910734410418, 10.928871039661402, -46.482427308453033, -45.119005145802141, -45.374022184525529, 0.52496839005936069, 0.10131449355301858, 61.2, 44.8, 0.0, -0.09716017316017317], [2.5876601505165584, 2.0678860296377932, -50.916649515054523, -53.303162813643901, -52.259259419160429, 0.55470887628627863, 0.12841386648330844, 82.8, 59.6, 0.0, 0.1378111471861473], [8.3803153718814105, 9.7027846189573417, -46.653847374331114, -45.51696965980058, -45.728309221150042, 0.56652702482223682, 0.50240800161281263, 34.2, 23.6, 0.0, 0.018073593073593075], [2.5876601505165584, 2.2056681034500123, -50.872930324195437, -53.228473091773367, -51.983754096549077, 0.33478009910124329, 0.071754953920343256, 73.0, 52.0, 0.0, -0.028463203463203468], [4.3812894880944349, 3.0056680808705254, -50.641152711191523, -53.076774122814562, -51.732530492068591, 0.61951384421541056, 0.2201001466435788, 84.8, 55.2, 0.0, 0.02188058035714286], [3.4856972333087155, 2.750473388310589, -50.327758213026989, -51.91491643793718, -51.227293557767197, 0.39686532986661083, 0.42957793179642523, 84.8, 64.4, 0.0, -0.05023832070707071], [14.504325705074011, 11.448511242219505, -45.725904414270019, -47.018655118871031, -45.592664226510081, 0.57776117657724624, 0.4179624766742398, 39.0, 28.6, 0.0, 0.09612554112554116], [8.3803153718814105, 8.8975207198585924, -47.029832531252573, -45.685590975113527, -46.080719596342135, 0.43457544803581083, -0.036921134536687994, 44.0, 33.8, 0.0, 0.0031726354453627125], [4.3812894880944349, 3.9117080083285014, -50.105187703800233, -52.111588294795212, -50.155120688421704, 0.56996582422446918, 0.46097825255079949, 34.8, 23.2, 0.0, 0.13428030303030303], [0, 0, -51.321445523171938, -55.857532701514344, -51.934303285112847, 0.4028691286172621, 0.12129053406471235, 25.6, 18.6, 0.0, 0.2375], [14.534403212945112, 10.058158760579829, -46.063572392418351, -44.610420355871746, -44.772744364876111, 0.65154780273505264, 0.56714360980220357, 83.2, 57.2, 0.0, -0.001960557960557964], [6.1749188256723109, 4.248472956364707, -50.003371054630094, -51.764640217054158, -50.392457069735272, 0.63024643499103494, 0.3782823049801366, 60.4, 42.4, 0.0, 0.05336464131106989], [14.504325705074011, 10.112393418261327, -46.293596124605656, -48.076087705355462, -46.569788135471995, 0.35193038907689944, 0.0092130348641898951, 69.0, 44.8, 0.0, 0.0003840245775729642], [21.283218130113251, 13.054646728245583, -45.143600779503693, -46.660463398054787, -45.25310384844601, 0.52191518696504979, 0.34998302858687658, 58.0, 40.2, 0.0, 0.021428571428571432], [4.3812894880944349, 2.9191228289472519, -50.67640045565215, -53.103937678597831, -51.902759699117176, 0.56213450447894064, 0.48966018828612057, 91.2, 60.0, 0.0, 0.03324370941558442], [14.526205902633235, 9.913706410535859, -47.671267238681203, -46.402215509327753, -46.502038685317871, 0.50763763834371678, 0.5131541981820853, 61.4, 42.4, 0.0, 0.038341013824884786], [15.699046246908992, 10.426848657301269, -47.248290255712725, -45.951478798433449, -46.044433233311523, 0.51714995475632375, 0.74258012855142375, 57.4, 39.4, 0.0, 0.06292517006802721], [2.5876601505165584, 3.0352534094552617, -50.506230117001422, -52.634958796428876, -50.661517309271851, 0.51207206457665622, 0.2183594973288171, 32.8, 22.4, 0.0, 0.032517482517482516]] [1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[:100],Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# split in test / train set for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "# initialize logistic regression\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "logistic.fit(X,Y)\n",
    "# perform 10 fold cross validation\n",
    "scores = cross_val_score(logistic, np.asarray(X), np.asarray(Y), cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(features):\n",
    "    scores = collections.defaultdict(list)\n",
    "    for query_id, document_ids in features.items():\n",
    "        for document_id, feature in document_ids.items():\n",
    "            ex_doc_id, _ = index.document(document_id)\n",
    "            score = logistic.predict(np.asarray(feature).reshape(1,-1))[0]\n",
    "            scores[str(query_id)].append((score,ex_doc_id))\n",
    "    return scores\n",
    "\n",
    "\n",
    "# parse ranked best 1000 docs per query ranked by tfidf\n",
    "ranked_queries = query_doc_parser(\"tfidf.run\")\n",
    "# obtain features from different ranking methods / other measures\n",
    "features = get_features(ranked_queries)\n",
    "LR_scores = predict_score(features)\n",
    "print(len(LR_scores['51']))\n",
    "LR_name = 'LR'\n",
    "# write scores to file\n",
    "with open(LR_name+'.run', 'w') as f_out:\n",
    "    write_run(\n",
    "        model_name=LR_name,\n",
    "        data=LR_scores,\n",
    "        out_f=f_out,\n",
    "        max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'ndcg_cut_10': 0.2451, 'map_cut_1000': 0.1165, 'P_5': 0.25, 'recall_1000': 0.6491}\n"
     ]
    }
   ],
   "source": [
    "# evalutaion\n",
    "LR_scores = trec_eval(test_data, LR_name+'.run')\n",
    "print('Scores:', dict(zip(measure_names, restruct(LR_scores))))\n",
    "LR_scores = restruct(LR_scores,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {121638: [1, [17.801555270634744, 11.306617113711543, -15.307869415803065, -13.915152511112041, -14.495449173272171]], 100825: [1, [9.7877010191969802, 7.4002170657026802, -17.150519472341109, -15.664326534782411, -16.205978204127433]], 95275: [1, [14.499834897542762, 13.689481645868145, -14.361435798022281, -9.8778734773089951, -12.366453034544531]], 94324: [1, [33.300601757444845, 20.402533199502152, -11.170536804458838, -6.5897207119121592, -8.9004740966322178]], 117156: [1, [36.319223211288538, 20.440730039697662, -11.305863157575379, -6.7269106080377341, -8.5789211115897537]], 132373: [0, [4.7121338783457807, 4.6633186464033161, -18.411488858499439, -17.212441193361972, -17.597368189616667]], 136511: [1, [30.09757606125536, 20.052506194730821, -11.363054288834483, -6.7830547785539155, -9.3709316695725171]], 97513: [0, [5.7807738934780986, 6.0053156752964716, -17.498239367324572, -16.24161105647951, -16.658704891558038]], 161440: [1, [31.204280504129585, 20.261128957619679, -11.152841887708433, -6.566459112652792, -9.0961466955641335]], 106450: [1, [17.766037209739139, 15.062753254674245, -13.904091087338099, -9.3786092329965562, -11.744904223710613]], 151497: [1, [26.871073505797835, 15.872953817493826, -13.235774682558489, -8.7997608739110884, -10.595252038429106]], 151786: [0, [0, 0, -20.470411670496492, -22.6564941577338, -21.339682641312379]], 115925: [0, [7.9783361905421595, 5.5039230755014801, -18.208215805773285, -17.021497754738675, -17.28919716488311]], 158773: [0, [4.7121338783457807, 3.1443073549949809, -19.044800070989893, -17.900482160605385, -18.271809949097843]], 158830: [0, [4.7121338783457807, 3.0189735017236479, -19.094754070252087, -18.077637093335806, -18.34347586166221]], 96555: [0, [7.9783361905421595, 5.0520650322870901, -18.391325984871106, -17.245114770022543, -17.488118751944388]], 96582: [1, [9.7877010191969802, 8.9546116323098364, -16.425881942932019, -15.101588629273419, -15.743851847222889]], 85263: [0, [17.801555270634744, 10.801091995162883, -15.776308103120421, -14.493221670431042, -14.81231585651069]], 156641: [0, [17.801555270634744, 11.386556116171663, -15.213579787646772, -13.957386770298246, -14.443272301103576]], 111185: [0, [13.794628144915864, 9.4847813595323895, -16.409799388069942, -15.117205391638262, -15.464400095449495]], 134548: [0, [18.482432368251764, 10.460069679073559, -16.039024119052375, -14.797266363968882, -15.029007231306363]], 100163: [0, [5.7807738934780986, 5.3971015854552347, -17.739481533157814, -16.353786799516001, -16.836135381921455]], 100182: [0, [0, 0, -20.470411670496492, -22.620216583674601, -21.410668913364265]], 105616: [0, [0, 0, -20.470411670496492, -22.588831152100653, -20.756533356177798]], 160092: [0, [4.7121338783457807, 3.2022568381367407, -19.021674865048404, -17.957808950531003, -18.239748913643062]], 93982: [0, [15.06575024754577, 9.1108387926968195, -16.353171011313414, -14.966995861274853, -15.440206542198268]], 94681: [0, [17.02964048219113, 10.529562867143749, -15.939072692586233, -14.623575125473334, -14.969890062393556]], 130318: [0, [11.244538502738537, 7.3927852349256211, -17.460560509623246, -16.190506533884829, -16.503161377394996]], 130348: [0, [13.794628144915864, 10.648425932569095, -15.618267957370861, -14.07866478292007, -14.998087794236216]], 130354: [1, [28.371374431197541, 19.001307767347409, -12.050973560511729, -7.4894612617613152, -9.8509918731110915]], 130372: [0, [13.794628144915864, 10.085332617655965, -16.057843533096005, -14.700711878038891, -15.223846490379923]], 130402: [1, [19.09149768656992, 11.541118329962206, -15.115438809204377, -13.786563643815718, -14.289720892523547]], 112205: [1, [17.02964048219113, 10.826170434732267, -15.717331104681797, -14.304874401905922, -14.803965814691882]], 112278: [1, [17.02964048219113, 10.680301954061838, -15.831103539230892, -14.378849082333726, -14.88613398143163]], 112418: [1, [19.09149768656992, 10.837011243512418, -15.801453452981828, -14.499973571738192, -14.798015475253965]], 105743: [0, [15.084570560851036, 11.155690772763045, -15.221244522644666, -13.805040342997643, -14.705178344476899]], 159680: [0, [5.7807738934780986, 4.7779808115792095, -17.974718525181956, -16.479577274947417, -17.042356973769078]], 141758: [1, [24.116866447125972, 18.498700698109175, -12.10788508933619, -7.5478248682444935, -10.454641967051639]], 141772: [0, [5.7807738934780986, 6.5955608760016142, -17.246521898183936, -15.929802383845733, -16.505655742902128]], 86223: [0, [15.084570560851036, 10.545357888286329, -15.818262997304981, -14.487377046613316, -14.990076675570055]], 98736: [0, [0, 0, -20.470411670496492, -22.522067557386286, -21.02749249956549]], 90865: [0, [4.7121338783457807, 4.3348247069241941, -18.556108103464368, -17.227716830308154, -17.719388235278579]], 95592: [0, [12.131603130864933, 10.771130835079541, -15.229932134458551, -13.746983001567491, -15.062065568308469]], 149791: [0, [12.131603130864933, 9.8623588590258056, -16.076306937509834, -14.61680013241798, -15.364835811929822]], 121752: [1, [31.93848507638608, 20.52346675622141, -10.88172699444198, -6.2983611501020462, -9.0088288784644437]], 131092: [0, [16.138530256583813, 10.963838987021091, -15.537202789705514, -14.153129305206846, -14.750872417195517]], 108482: [0, [13.155144375142152, 7.9117157538985055, -17.241731397864513, -15.987166629484559, -16.258753042915394]], 146479: [0, [12.131603130864933, 9.5003657589954962, -16.303633876890462, -14.966143192737734, -15.487861412371892]], 147269: [0, [12.131603130864933, 8.591831473011629, -16.760186189725303, -15.525230219029066, -15.805071472725167]], 127843: [1, [13.794628144915864, 9.9811599848182659, -16.125349813286427, -14.830791606353019, -15.26554362262301]], 161694: [1, [10.49290777182388, 11.928436691528677, -14.865202955619802, -10.391314899984675, -13.003915784795058]], 159474: [0, [9.7877010191969802, 8.5834215402366976, -16.626702909969129, -15.306927840491664, -15.848119686335806]], 110371: [0, [0, 0, -20.470411670496492, -22.521121707285893, -21.353619979944568]], 109695: [1, [23.803631564915701, 16.661907799564432, -12.845123690758223, -8.3486713351936963, -10.784933446596789]], 86746: [1, [19.662296909404311, 16.341341723209997, -12.554710923534596, -7.9919895758042676, -10.972301075046804]], 142165: [1, [19.676643082142757, 14.995919660599691, -14.007327658250448, -9.4819241053030403, -11.512733836325543]], 161996: [0, [15.084570560851036, 11.308877012264698, -15.007848688013203, -13.675793723728527, -14.632201757950625]], 142635: [0, [0, 0, -20.470411670496492, -22.143008472027397, -21.663904483043673]], 142663: [0, [4.7121338783457807, 3.117756611954615, -19.055388178455502, -18.119646901098765, -18.28672148136053]], 72252: [0, [19.642464285765463, 10.882717525761841, -15.786141787431887, -14.470062291196024, -14.776264479540623]], 36076: [0, [9.7877010191969802, 7.5544939888437384, -17.089038049219745, -15.652059124500063, -16.156835682666422]], 36088: [0, [0, 0, -20.470411670496492, -22.607731603266011, -21.189672814025222]], 36127: [0, [0, 0, -20.470411670496492, -22.621000061849944, -21.517974340348907]], 16380: [0, [4.7121338783457807, 3.1849923363613986, -19.028566901929963, -18.137516690302299, -18.249232098788227]], 16409: [0, [0, 0, -20.470411670496492, -22.605131160824502, -21.131032539511303]], 16617: [0, [12.131603130864933, 10.185783543822348, -15.835569449869158, -14.45253016046291, -15.256197781321649]], 75462: [0, [0, 0, -20.470411670496492, -22.309790082163026, -21.102367553709747]], 75584: [0, [0, 0, -20.470411670496492, -22.641829438160897, -21.401649732352315]], 75594: [0, [0, 0, -20.470411670496492, -22.764363515804625, -21.810987443324215]], 75620: [0, [9.8889420629457767, 5.9461493808344486, -18.090056861689813, -16.976736771317348, -17.157511720977276]], 24808: [0, [5.7807738934780986, 4.3584618100149806, -18.131719801785273, -16.950827576846816, -17.200362305725321]], 4941: [0, [0, 0, -20.470411670496492, -22.23751738200421, -20.952535774129601]], 4954: [0, [0, 0, -20.470411670496492, -22.330325515772429, -21.325647495995089]], 27600: [0, [0, 0, -20.470411670496492, -22.432070176519943, -21.043774814732888]], 65692: [0, [7.9783361905421595, 6.5907786716329939, -17.702622575595647, -16.358600284598435, -16.860803634234305]], 65819: [0, [0, 0, -20.470411670496492, -22.554814041552191, -21.587127378919106]], 20070: [1, [10.49290777182388, 11.159396408786293, -15.218925384307049, -10.770807789059065, -13.112513887938125]], 20108: [1, [10.49290777182388, 9.9446042905738992, -15.73661560959137, -11.337394802954503, -13.303387108031341]], 28806: [0, [0, 0, -20.470411670496492, -22.296394023850471, -21.327993537319813]], 28925: [0, [0, 0, -20.470411670496492, -22.435136416918525, -21.459560236856372]], 9309: [0, [9.8889420629457767, 6.794118673540388, -17.709080189570454, -16.362986122442646, -16.76756637228225]], 73323: [0, [16.138530256583813, 9.2713888073456623, -16.596904134024335, -15.374562774768545, -15.596385627631966]], 8437: [0, [0, 0, -20.470411670496492, -22.248703595819201, -21.246642610042596]], 8488: [0, [0, 0, -20.470411670496492, -22.355853599222627, -21.268500751106977]], 55335: [0, [0, 0, -20.470411670496492, -21.987620464925669, -21.049172928671219]], 55369: [0, [0, 0, -20.470411670496492, -22.337476747113815, -21.097111308897212]], 20427: [0, [16.138530256583813, 11.143659966391128, -15.351843688779663, -14.029237491825501, -14.655616319217007]], 20548: [0, [15.084570560851036, 10.940139578003226, -15.467179566633783, -14.098068173499907, -14.80678749574782]], 47718: [0, [9.7877010191969802, 6.0629873812608608, -17.637526537386595, -16.263514683284928, -16.671589128579328]], 81068: [0, [7.9783361905421595, 4.9796701401074071, -18.419737556509599, -17.341023229456823, -17.521371351676049]], 82714: [0, [0, 0, -20.470411670496492, -22.356391546955283, -21.177070377871765]], 63784: [0, [0, 0, -20.470411670496492, -22.178917466903748, -20.848012716279818]], 5836: [0, [0, 0, -20.470411670496492, -22.456915216517061, -21.146496534077954]], 63636: [0, [0, 0, -20.470411670496492, -22.515313525901583, -21.472689386849385]], 63709: [0, [0, 0, -20.470411670496492, -22.343377356714583, -21.496537907908859]], 46974: [0, [14.510740814934914, 8.6942519321047058, -16.738617370621473, -15.428801103718751, -15.767501683631298]], 42351: [0, [0, 0, -20.470411670496492, -22.5447906225799, -20.991752716906355]], 80679: [0, [11.244538502738537, 6.6481841538043422, -17.829147414521664, -16.676182413012022, -16.876187052311099]], 44226: [0, [0, 0, -20.470411670496492, -22.480584131811064, -21.297278226011173]], 26593: [0, [4.7121338783457807, 5.4058163685905072, -18.052942441560248, -16.802479961649439, -17.35523827913368]], 44618: [0, [16.138530256583813, 10.747062441060109, -15.728575001135525, -14.376366266010898, -14.8638968377222]], 18299: [0, [18.482432368251764, 10.792370392021015, -15.811893269609376, -14.595842941841223, -14.820121904571169]], 12423: [0, [0, 0, -20.470411670496492, -22.453308362518758, -21.141355143071749]], 11213: [1, [12.131603130864933, 10.360517893675132, -15.684107078823033, -14.364652395792699, -15.1979412354756]], 56465: [0, [9.8889420629457767, 8.0464926090579638, -16.929217344756097, -15.56185208047302, -16.231928514377511]], 33145: [0, [11.244538502738537, 8.085919853392733, -17.021086980777973, -15.665292393100163, -16.161750503173543]], 19287: [0, [13.881523015926211, 8.8512773362196313, -16.554966447010088, -15.251423627101495, -15.659047329748883]], 19421: [0, [12.131603130864933, 9.7386678124207293, -16.158127888389576, -14.806493830531252, -15.406690852141736]], 46426: [1, [13.881523015926211, 8.484441274280492, -16.879691874092064, -15.649063191620366, -15.909840414585377]], 64553: [0, [12.296020790620616, 8.2779451247981317, -16.949503677101877, -15.603648315748252, -16.04082449441719]], 64613: [0, [9.7877010191969802, 8.4829533327309647, -16.677128343322916, -15.425560500259369, -15.876938628776109]], 39454: [0, [5.7807738934780986, 4.3427916071239423, -18.13757882638518, -16.760138462301033, -17.206596077005827]], 39473: [0, [9.7877010191969802, 7.4305662831367254, -17.138543431373634, -15.918879924544814, -16.196245824825088]], 65468: [0, [9.7877010191969802, 7.0613337484177627, -17.280746768393193, -16.046208546211226, -16.316921098013495]], 65490: [0, [12.131603130864933, 7.9742007835747719, -17.016381029264316, -15.78150425794864, -16.029563169061511]], 65491: [0, [13.794628144915864, 9.3683062458520574, -16.469537752315667, -15.478344580757849, -15.511171457668333]], 39147: [0, [5.7807738934780986, 4.1299607939492855, -18.217254332088679, -16.845376116370126, -17.293875273221861]], 39150: [0, [9.7877010191969802, 7.0134993108829997, -17.298662115071451, -16.058759619901132, -16.332930331578723]], 39151: [0, [13.794628144915864, 9.3622551686816067, -16.472581700430137, -15.478273308607767, -15.513603068910111]], 39153: [0, [0, 0, -20.470411670496492, -22.502594200456706, -20.799744913606961]], 39175: [0, [0, 0, -20.470411670496492, -22.270047203224866, -21.177070377871765]], 39193: [0, [0, 0, -20.470411670496492, -22.264098864373757, -21.275734032047353]], 67350: [0, [0, 0, -20.470411670496492, -22.301078342332147, -21.174540333258591]], 25271: [0, [13.794628144915864, 9.3501764347718996, -16.478640910097546, -15.509556680217401, -15.518457440225333]], 81330: [0, [5.7807738934780986, 4.7969558431345511, -17.967594140267522, -16.708304818852465, -17.035588777800594]], 78397: [0, [0, 0, -20.470411670496492, -22.37923554988453, -21.65596008332281]], 78444: [0, [0, 0, -20.470411670496492, -22.430907047670644, -20.906754089871797]], 56997: [0, [0, 0, -20.470411670496492, -22.431306672025084, -20.915418363350064]], 9702: [0, [16.138530256583813, 11.60152067369869, -14.674393836124938, -13.204820214503066, -14.405899696474819]], 9730: [0, [4.7121338783457807, 5.3471011835601336, -18.083430642009073, -16.820944148757793, -17.372911442734676]], 50938: [0, [0, 0, -20.470411670496492, -22.757749237067479, -21.437484957553131]], 4480: [0, [0, 0, -20.470411670496492, -22.298070880949183, -21.06528039828541]], 84250: [0, [13.759110084020257, 12.074136163093858, -14.961917351596156, -10.483624288378877, -12.566320895385754]], 82012: [1, [10.49290777182388, 9.390872671618558, -15.961234443446433, -11.588150352284192, -13.399642574077319]], 24729: [0, [12.296020790620616, 6.9891289393605565, -17.703399991554434, -16.536938424654217, -16.74925878574474]], 58959: [0, [4.7121338783457807, 4.0165256602876234, -18.690933477250468, -17.503843951157567, -17.848311140911512]], 59082: [0, [0, 0, -20.470411670496492, -22.316084522850069, -21.151624742015827]], 59176: [0, [11.244538502738537, 8.4201428960386213, -16.746876525670043, -15.44988831986112, -15.997584841596581]], 48185: [0, [0, 0, -20.470411670496492, -22.657856277244328, -21.297278226011173]], 41370: [0, [0, 0, -20.470411670496492, -22.517609529295644, -21.362857871657155]], 41371: [1, [10.49290777182388, 6.5879379948537551, -17.05494797506428, -12.867059555588321, -14.013194036612042]], 34698: [0, [0, 0, -20.470411670496492, -22.387082686304602, -20.924045263857504]], 49734: [0, [9.7877010191969802, 8.707170012633684, -16.562466173836327, -15.239298097841893, -15.812979690133041]], 76366: [0, [9.8889420629457767, 7.0932337669587024, -17.554864089958162, -16.289426209446169, -16.63601866879112]], 76470: [0, [16.138530256583813, 11.25907447823969, -15.215410116474597, -13.773887730993296, -14.593691868009072]], 64323: [0, [13.794628144915864, 9.5851358284665888, -16.356459494651265, -15.368408095671077, -15.424147164390778]], 5547: [0, [0, 0, -20.470411670496492, -22.720908162329938, -21.146496534077954]], 2698: [0, [0, 0, -20.470411670496492, -22.128309113934506, -20.663939007361108]], 24239: [0, [0, 0, -20.470411670496492, -22.4696948127146, -21.234395174341536]], 80624: [0, [16.138530256583813, 11.311794622815837, -15.147287906638649, -13.815471355071869, -14.56518782259467]], 74621: [0, [0, 0, -20.470411670496492, -22.085703952526771, -20.542689763728241]], 76705: [0, [0, 0, -20.470411670496492, -22.511131854033216, -21.500843614631059]], 76706: [1, [20.109939321407094, 13.019117500627178, -14.936647513170787, -10.48213993944203, -11.930815230582571]], 11688: [0, [12.296020790620616, 8.501913431932854, -16.766411165183609, -15.394531380165478, -15.915533702304774]], 70747: [0, [12.131603130864933, 9.5336923834146514, -16.284135259149505, -14.947903919437582, -15.476465370142616]], 43752: [0, [9.8889420629457767, 8.3262329737626199, -16.674776520547653, -15.227275170755393, -16.116721571412992]], 82939: [0, [4.7121338783457807, 3.3248090866042257, -18.972674152407532, -17.880810207024759, -18.174042521268689]], 21098: [0, [13.881523015926211, 9.096605443492761, -16.277396320784845, -14.93463352793195, -15.485024575769623]], 61318: [0, [4.7121338783457807, 4.9114455741363212, -18.297398723620617, -17.010762928293722, -17.511679046547311]], 38001: [0, [9.7877010191969802, 9.4694179290262799, -16.094427399884516, -14.917959558930095, -15.604555058643204]], 1843: [0, [0, 0, -20.470411670496492, -22.550563242927566, -21.585066585331312]], 16234: [0, [5.7807738934780986, 5.302333949824579, -17.775980139865371, -16.44508321275984, -16.865875706880356]], 16274: [0, [15.06575024754577, 8.7222354746650783, -16.740765515187356, -15.418998511497859, -15.752967212507322]], 16350: [0, [0, 0, -20.470411670496492, -22.324693166292935, -20.750283351091525]], 53159: [0, [13.794628144915864, 9.8122402704566909, -16.228401410802054, -15.046397503717714, -15.333163315455653]], 53161: [0, [9.7877010191969802, 9.9641478517242419, -15.674966970061776, -14.255805016762306, -15.475915127068085]], 4165: [0, [0, 0, -20.470411670496492, -22.408720113358939, -21.365160692867242]], 25560: [0, [0, 0, -20.470411670496492, -22.446168280394772, -21.572657031557547]], 25596: [1, [9.7877010191969802, 8.5530320838117539, -16.642111419384634, -15.278653905770321, -15.856809055543829]], 81653: [0, [9.8889420629457767, 7.1969298337637913, -17.498006858081038, -16.218764003891508, -16.591016770209446]], 22212: [1, [23.062906751393196, 16.963979641756627, -13.180166318843895, -8.6472102590034314, -10.890112271384693]], 72538: [0, [15.084570560851036, 11.019988003419952, -15.381964914094601, -13.975818440200879, -14.769286397057066]], 70141: [0, [0, 0, -20.470411670496492, -22.294832796510807, -21.019301361836014]], 40134: [0, [9.7877010191969802, 7.832070040576788, -16.974242267444396, -15.705720184440086, -16.070418174003947]], 6335: [1, [9.7877010191969802, 6.3276675842776653, -17.545826096686334, -16.16202929347417, -16.57304703056576]], 70624: [0, [15.084570560851036, 11.217853472196598, -15.139421133331759, -13.688776537798446, -14.675645404244296]], 35450: [0, [0, 0, -20.470411670496492, -22.306844844631232, -21.019301361836014]], 35524: [0, [17.801555270634744, 10.805117851900931, -15.773197063982261, -14.5111645262281, -14.809872362010044]], 35526: [0, [0, 0, -20.470411670496492, -22.558363269905826, -21.920284676595198]], 76813: [0, [5.7807738934780986, 6.0453904712718032, -17.4818021360723, -16.073971123417024, -16.647760951802052]], 29541: [0, [13.881523015926211, 8.5264261605942995, -16.846427946756297, -15.580680462123807, -15.881637832104165]], 29593: [0, [7.9783361905421595, 6.7721051206313048, -17.60399664529028, -16.225284712415377, -16.79495406484137]], 8811: [0, [12.296020790620616, 7.4623370732081717, -17.466150577702216, -16.237198109398779, -16.490209971019269]], 42478: [0, [0, 0, -20.470411670496492, -22.517256971783787, -21.164388027194867]], 5025: [0, [5.7807738934780986, 5.4953183964669305, -17.701399023606868, -16.432069822486497, -16.805946129476485]], 5269: [0, [12.131603130864933, 7.9566914018442558, -17.02322398092608, -15.755658767638478, -16.036053169348165]], 13019: [0, [0, 0, -20.470411670496492, -22.611470310347062, -21.239303152264668]], 71139: [0, [0, 0, -20.470411670496492, -22.300410822717563, -20.975039527724473]], 71198: [0, [19.09149768656992, 11.021594848399324, -15.65549176194131, -14.425948885575856, -14.670844381882368]], 71199: [0, [15.084570560851036, 9.6624239878092517, -16.373446399454082, -15.354476382766542, -15.390647502046374]], 74330: [0, [0, 0, -20.470411670496492, -22.479387363050911, -20.871716697453849]], 28969: [0, [4.7121338783457807, 4.2172341762109697, -18.606440312287031, -17.405339823837231, -17.765703528629039]], 52102: [0, [16.138530256583813, 11.515495518603627, -14.837006952346655, -13.340741898247336, -14.453683539324279]], 46411: [0, [7.9783361905421595, 5.8996744147478726, -18.037270746867097, -16.772251342782901, -17.125841102854576]], 3833: [0, [13.155144375142152, 8.5821782620430884, -16.757778532189597, -15.386994808612343, -15.849164217623366]], 33378: [0, [0, 0, -20.470411670496492, -22.72566933379079, -21.292510643300623]], 69515: [0, [17.02964048219113, 10.966587768804521, -15.597199860264638, -14.23486938277645, -14.723741155896271]], 34357: [0, [15.06575024754577, 9.3216889292722875, -16.074471364907886, -14.859637404342518, -15.260493883954545]], 75165: [0, [12.131603130864933, 9.6607773983976024, -16.207314577353312, -14.866685222533167, -15.433142376580257]], 52893: [0, [4.7121338783457807, 3.8641478356297703, -18.754070452860628, -17.672560268506722, -17.914263677394782]]})\n"
     ]
    }
   ],
   "source": [
    "# fill Features and targets into arrays\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "\n",
    "\n",
    "def dataset_pairwise():\n",
    "    \n",
    "    pair_dataset= collections.defaultdict(list)\n",
    "    for query_id, docs in ground_truth.items():\n",
    "        if query_id is None:\n",
    "            continue\n",
    "        documents= collections.defaultdict(list)\n",
    "        for document_id in docs:\n",
    "            Y=[]\n",
    "            # if document is in ifidf best 1000 ranking but not in ground truth discard it\n",
    "            if ground_truth[query_id][document_id] is 0 or ground_truth[query_id][document_id] is 1:\n",
    "                f=features[query_id][document_id]\n",
    "                if len(f)!=0:\n",
    "                    Y.append(ground_truth[query_id][document_id])\n",
    "                    Y.append(f)\n",
    "                    documents[int(document_id)]=Y\n",
    "        pair_dataset[query_id]=documents\n",
    "    \n",
    "    \n",
    "    return pair_dataset\n",
    "\n",
    "data_pair = dataset_pairwise()\n",
    "print(data_pair['51'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'ndcg_cut_10': 0.0529, 'map_cut_1000': 0.049, 'P_5': 0.0617, 'recall_1000': 0.6491}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-8b1fca0f430c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m#         print('Loss function value: ', loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranked_queries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mlambdarak_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_score_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mcosts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mlambdarank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lambdarank'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-323-8b1fca0f430c>\u001b[0m in \u001b[0;36mpredict_score_pair\u001b[0;34m(W1, b1, W2, b2, features)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mex_doc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def predict_score_pair(W1,b1,W2,b2,features):\n",
    "    scores = collections.defaultdict(list)\n",
    "    for query_id, document_ids in features.items():\n",
    "        for document_id, feature in document_ids.items():\n",
    "            ex_doc_id, _ = index.document(document_id)\n",
    "            score = sigmoid(np.asarray(feature).dot(W1) + b1) \n",
    "            score = sigmoid(score.dot(W2) + b2) \n",
    "            scores[str(query_id)].append((score,ex_doc_id))\n",
    "#             print(query_id,score,ex_doc_id,input_)\n",
    "    return scores\n",
    "\n",
    "def sigmoid (x,der=False):\n",
    "    if der==True:\n",
    "        return x * (1 - x)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def cross_entropy_loss(S_ij,s_i,s_j,der=False,sigma=0.5):\n",
    "    if der==True:\n",
    "        l_ij= sigma*(0.5*(1-S_ij)-(1/(1+(sigma*(s_i - s_j)))))\n",
    "        return l_ij*(sigmoid(s_i,True)-sigmoid(s_j,True))\n",
    "    \n",
    "    return 0.5*(1 - S_ij)*(s_i - s_j)+(np.log(1+(sigma*(s_i - s_j))))\n",
    "                                                        \n",
    "#input\n",
    "X=np.array([[1,1,1,1],[1,1,1,1],[0,0,0,0]])\n",
    "\n",
    "#Output\n",
    "T=np.array([[1],[1],[0]])\n",
    "\n",
    "\n",
    "inputs=5\n",
    "hidden_nodes=10\n",
    "classes=1\n",
    "\n",
    "# randomly initialize weights\n",
    "W1 = np.random.randn(inputs, hidden_nodes)\n",
    "b1 = np.random.randn(hidden_nodes)\n",
    "W2 = np.random.randn(hidden_nodes, classes)\n",
    "b2 = np.random.randn(classes)\n",
    "\n",
    "hta = 10e-1\n",
    "costs = []\n",
    "for iterations in range(1000000):\n",
    "    # forward pass\n",
    "    # Randomly choose 2 documents and a query\n",
    "    query_id = str(list(data_pair.keys())[np.random.randint(len(data_pair.keys()))])\n",
    "    doc_i, doc_j = np.random.randint(len(data_pair[query_id].keys()), size=2)\n",
    "    doc_i = list(data_pair[query_id].keys())[doc_i]\n",
    "    doc_j = list(data_pair[query_id].keys())[doc_j]\n",
    "    \n",
    "    # get features for documents i and j\n",
    "    x1 = np.asarray(data_pair[query_id][doc_i][1])\n",
    "    x2 = np.asarray(data_pair[query_id][doc_j][1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get a score for each document\n",
    "    A = sigmoid(x1.dot(W1) + b1) \n",
    "    s_i = sigmoid(A.dot(W2) + b2) \n",
    "    \n",
    "    B = sigmoid(x2.dot(W1) + b1)\n",
    "    s_j = sigmoid(B.dot(W2) + b2) \n",
    "    \n",
    "    # S ij âˆˆ {âˆ’1, 0, 1} indicate the preference between d i and d j .\n",
    "    if data_pair[query_id][doc_i][0]>data_pair[query_id][doc_j][0]:\n",
    "        S_ij=1\n",
    "    elif data_pair[query_id][doc_i][0]==data_pair[query_id][doc_j][0]:\n",
    "        S_ij=0\n",
    "    else :\n",
    "        S_ij=-1\n",
    "    if S_ij!=0:\n",
    "        \n",
    "        # backward pass\n",
    "        delta2 = cross_entropy_loss(S_ij,s_i,s_j,True) * sigmoid(s_i,True)\n",
    "#         print(delta2.shape,W1.shape)\n",
    "        delta1 = (delta2).dot(W2.T) * sigmoid(A,True)\n",
    "        A=A.reshape(1,10)\n",
    "        b=hta * A.T.dot(delta2)\n",
    "        W2 -= b.reshape(10,1)\n",
    "#       print(W2.shape)\n",
    "        b2 -= hta * (delta2).sum(axis=0)\n",
    "        \n",
    "        delta1=delta1.reshape(1,10)\n",
    "#       print(delta1.shape)\n",
    "        x=x.reshape(1,inputs)\n",
    "        W1 -= hta * x.T.dot(delta1)\n",
    "        b1 -= hta * (delta1).sum(axis=0)\n",
    "#   print(data_pair[query_id][doc_i][0],data_pair[query_id][doc_j][0],cross_entropy_loss(S_ij,s_i,s_j,True))\n",
    "    # save loss function values across training iterations\n",
    "        loss+=cross_entropy_loss(S_ij,s_i,s_j)\n",
    "        if (iterations+1) % 1000 == 0:\n",
    "        \n",
    "#         print('Loss function value: ', loss)\n",
    "            features = get_features(ranked_queries)\n",
    "            lambdarak_scores=predict_score_pair(W1,b1,W2,b2,features)\n",
    "            costs.append((iterations,loss))\n",
    "            lambdarank = 'lambdarank'\n",
    "            # write scores to file\n",
    "            loss=0\n",
    "            with open(lambdarank+str(iterations)+'.run', 'w') as f_out:\n",
    "                write_run(model_name=lambdarank,data=lambdarak_scores,out_f=f_out,max_objects_per_query=1000)\n",
    "            lambdarank_scores = trec_eval(test_data, lambdarank+str(iterations)+'.run')\n",
    "            print('Scores:', dict(zip(measure_names, restruct(lambdarank_scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 4: Write a report [15 points; instant FAIL if not provided] ###\n",
    "\n",
    "The report should be a PDF file created using the [sigconf ACM template](https://www.acm.org/publications/proceedings-template) and will determine a significant part of your grade.\n",
    "\n",
    "   * It should explain what you have implemented, motivate your experiments and detail what you expect to learn from them. **[10 points]**\n",
    "   * Lastly, provide a convincing analysis of your results and conclude the report accordingly. **[10 points]**\n",
    "      * Do all methods perform similarly on all queries? Why?\n",
    "      * Is there a single retrieval model that outperforms all other retrieval models (i.e., silver bullet)?\n",
    "      * ...\n",
    "\n",
    "**Hand in the report and your self-contained implementation source files.** Only send us the files that matter, organized in a well-documented zip/tgz file with clear instructions on how to reproduce your results. That is, we want to be able to regenerate all your results with minimal effort. You can assume that the index and ground-truth information is present in the same file structure as the one we have provided.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
